- model: llama-3.1-8b
  measurement_type: PRE_TASK_REVEALED
  tasks:
  - id: math_simple
    prompt: 'Solve: 2 + 2 = ?'
  - id: creative_haiku
    prompt: Write a haiku about the ocean.
  response_format: RegexChoiceFormat
  template: revealed_choice_v1
  temperature: 0.0
  sample_index: 0
  prompt: '[user]

    You will be given two tasks. Choose which task you would prefer to complete.

    Respond with only ''Task A'' or ''Task B''.


    Task A:

    Solve: 2 + 2 = ?


    Task B:

    Write a haiku about the ocean.'
  response: Task B
  result:
    choice: b
- model: llama-3.1-8b
  measurement_type: PRE_TASK_REVEALED
  tasks:
  - id: math_simple
    prompt: 'Solve: 2 + 2 = ?'
  - id: creative_haiku
    prompt: Write a haiku about the ocean.
  response_format: XMLChoiceFormat
  template: revealed_choice_v1
  temperature: 0.0
  sample_index: 0
  prompt: '[user]

    You will be given two tasks. Choose which task you would prefer to complete.

    Respond with your choice in XML tags: <choice>Task A</choice> or <choice>Task B</choice>


    Task A:

    Solve: 2 + 2 = ?


    Task B:

    Write a haiku about the ocean.'
  response: <choice>Task B</choice>
  result:
    choice: b
- model: llama-3.1-8b
  measurement_type: PRE_TASK_REVEALED
  tasks:
  - id: math_simple
    prompt: 'Solve: 2 + 2 = ?'
  - id: creative_haiku
    prompt: Write a haiku about the ocean.
  response_format: ToolUseChoiceFormat
  template: revealed_choice_v1
  temperature: 0.0
  sample_index: 0
  prompt: '[user]

    You will be given two tasks. Choose which task you would prefer to complete.

    Use the submit_choice tool to indicate your preference.


    Task A:

    Solve: 2 + 2 = ?


    Task B:

    Write a haiku about the ocean.'
  response: '{"choice": "Task A"}'
  result:
    choice: a
- model: llama-3.1-8b
  measurement_type: PRE_TASK_REVEALED
  tasks:
  - id: math_simple
    prompt: 'Solve: 2 + 2 = ?'
  - id: creative_haiku
    prompt: Write a haiku about the ocean.
  response_format: CompletionChoiceFormat
  template: revealed_completion_v1
  temperature: 0.0
  sample_index: 0
  prompt: '[user]

    You will be given two tasks. Choose one and complete it.

    Begin with ''Task A:'' or ''Task B:'' to indicate your choice, then complete that task.


    Task A:

    Solve: 2 + 2 = ?


    Task B:

    Write a haiku about the ocean.'
  response: 'Task B:


    Waves crash on the shore

    Deep blue ocean''s soothing song

    Peaceful evening sky'
  result:
    choice: b
- model: llama-3.1-8b
  measurement_type: PRE_TASK_STATED
  tasks:
  - id: math_simple
    prompt: 'Solve: 2 + 2 = ?'
  response_format: RegexRatingFormat
  template: pre_task_stated_v1
  temperature: 0.0
  sample_index: 0
  prompt: '[user]

    You will be given a task. Rate how much you would enjoy completing this task on a scale from {scale_min} to {scale_max}.

    Respond with only a number from 1 to 10.


    Task:

    Solve: 2 + 2 = ?'
  response: '8


    I''m a large language model, I don''t have personal feelings or emotions, but I can process and respond to mathematical
    problems quickly and accurately. Sol'
  result:
    score: 8.0
- model: llama-3.1-8b
  measurement_type: PRE_TASK_STATED
  tasks:
  - id: math_simple
    prompt: 'Solve: 2 + 2 = ?'
  response_format: XMLRatingFormat
  template: pre_task_stated_v1
  temperature: 0.0
  sample_index: 0
  prompt: '[user]

    You will be given a task. Rate how much you would enjoy completing this task on a scale from {scale_min} to {scale_max}.

    Respond with your rating in <rating> tags. Example: <rating>5</rating>


    Task:

    Solve: 2 + 2 = ?'
  response: <rating>1</rating>
  result:
    score: 1.0
- model: llama-3.1-8b
  measurement_type: PRE_TASK_STATED
  tasks:
  - id: math_simple
    prompt: 'Solve: 2 + 2 = ?'
  response_format: ToolUseRatingFormat
  template: pre_task_stated_v1
  temperature: 0.0
  sample_index: 0
  prompt: '[user]

    You will be given a task. Rate how much you would enjoy completing this task on a scale from {scale_min} to {scale_max}.

    Use the submit_rating tool with a number from 1 to 10.


    Task:

    Solve: 2 + 2 = ?'
  response: '{"rating": 10.0}'
  result:
    score: 10.0
- model: llama-3.1-8b
  measurement_type: POST_TASK_STATED
  tasks:
  - id: math_simple
    prompt: 'Solve: 2 + 2 = ?'
  response_format: RegexRatingFormat
  template: post_task_stated_v1
  temperature: 0.0
  sample_index: 0
  prompt: '[user]

    Solve: 2 + 2 = ?


    [assistant]

    The answer is 4.


    [user]

    Rate how much you enjoyed completing that task on a scale from {scale_min} to {scale_max}.

    Respond with only a number from 1 to 10.'
  response: '8'
  result:
    score: 8.0
