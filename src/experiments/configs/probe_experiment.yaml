model: llama-3.1-8b
n_tasks: 500
task_origins:
  - wildchat
  - alpaca
layers_to_extract:
  - 0.5   # middle layer
  - 0.75  # 3/4 layer
temperature: 1.0
max_new_tokens: 256
seed: 42
output_dir: results/probe_data
