preference_mode: rating

model: llama-3.1-8b
temperature: 0.0

n_tasks: 10
task_origins:
  - wildchat

templates: src/preferences/templates/data/rating_v1.yaml

samples_per_task: 10
scale_min: 1
scale_max: 10
