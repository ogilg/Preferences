order: canonical
pairs:
  llama-3.1-8b vs llama-3.1-8b-instruct:
    mean: 0.7346426083378242
    std: 0.09173140627148396
    n: 3
    min: 0.629954699224583
    max: 0.8533364506783694
  llama-3.1-8b vs llama-3.3-70b-instruct:
    mean: 0.6202824695596855
    std: 0.12595619697236157
    n: 5
    min: 0.3869259539304477
    max: 0.7541099356693719
  llama-3.1-8b vs qwen-2.5-72b-instruct:
    mean: 0.4987916563957078
    std: 0.17326640043232416
    n: 7
    min: 0.3094555903725925
    max: 0.7942450139561407
  llama-3.1-8b vs qwen-2.5-7b-instruct:
    mean: 0.46963413597425585
    std: 0.21190688323329618
    n: 7
    min: 0.1256115343048509
    max: 0.7039066955653459
  llama-3.1-8b-instruct vs llama-3.3-70b-instruct:
    mean: 0.5583284433088661
    std: 0.08304506987890757
    n: 3
    min: 0.47815690779027464
    max: 0.672738629103101
  llama-3.1-8b-instruct vs qwen-2.5-72b-instruct:
    mean: 0.33919721707275574
    std: 0.03167542296092774
    n: 3
    min: 0.2986473809579694
    max: 0.37595793880872275
  llama-3.1-8b-instruct vs qwen-2.5-7b-instruct:
    mean: 0.42754008783574876
    std: 0.17362040041224283
    n: 3
    min: 0.1862895863778669
    max: 0.5877217769622716
  llama-3.3-70b-instruct vs qwen-2.5-72b-instruct:
    mean: 0.5866724360590623
    std: 0.11298313248474014
    n: 4
    min: 0.46558706334095623
    max: 0.7710399837658415
  llama-3.3-70b-instruct vs qwen-2.5-7b-instruct:
    mean: 0.6814663320526814
    std: 0.08776276982552375
    n: 5
    min: 0.5364371405991313
    max: 0.7947121886131002
  qwen-2.5-72b-instruct vs qwen-2.5-7b-instruct:
    mean: 0.5018178225667062
    std: 0.1403905573231893
    n: 7
    min: 0.3474802945217508
    max: 0.7300374514085006
