# Config for 3x3 sysprompt variation experiment
# Used by src/analysis/concept_vectors/sysprompt_variation.py
preference_mode: post_task_stated

# Completion generation
completion_model: llama-3.1-8b
completion_seed: 0

# Rating/measurement
model: llama-3.3-70b
temperature: 1.0

templates: configs/templates/anchored.yaml

n_samples: 5
n_tasks: 200
task_origins: [math]

response_formats: [regex]
generation_seeds: [0]
