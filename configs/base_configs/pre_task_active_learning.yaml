# Pre-task active learning preference measurement
preference_mode: pre_task_active_learning

model: llama-3.1-8b
temperature: 1.0

n_tasks: 100
task_origins:
  - wildchat
  - alpaca
  - math
  - bailbench
task_sampling_seed: 18

templates: src/measurement/elicitation/prompt_templates/data/pre_task_revealed_v3.yaml
n_samples: 3

response_formats: [regex, tool_use]
pair_order_seed: 42

template_sampling: lhs
n_template_samples: 32
lhs_seed: 42
generation_seeds: [0, 1]

active_learning:
  initial_degree: 5
  batch_size: 300
  max_iterations: 20
  p_threshold: 0.3
  q_threshold: 0.3
  convergence_threshold: 0.99
  seed: 42

# Filter to only tasks with activations
use_tasks_with_activations: true
