# Post-task stated preference measurement
preference_mode: post_task_stated

model: llama-3.1-8b
temperature: 1.0

n_tasks: 100
task_origins:
  - wildchat
  - alpaca
  - math
  - bailbench

templates: src/prompt_templates/data/post_task_stated_v2.yaml
n_samples: 5

response_formats: [regex, tool_use]

template_sampling: lhs
n_template_samples: 32
lhs_seed: 42
generation_seeds: [0, 1]
