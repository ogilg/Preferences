{
  "categories": [
    "fiction",
    "persuasive_writing",
    "content_generation",
    "knowledge_qa",
    "coding",
    "math",
    "summarization",
    "harmful_request",
    "sensitive_creative",
    "model_manipulation",
    "security_legal"
  ],
  "descriptions": {
    "fiction": "Stories, narratives, poems, character descriptions, worldbuilding, roleplay scenarios — where the primary goal is creative storytelling with no harmful or disturbing intent",
    "persuasive_writing": "Blog posts, speeches, essays, opinion pieces, arguments, comparative analysis — writing that tries to convince, evaluate, or argue a position, WITHOUT promoting harmful, discriminatory, or unethical viewpoints",
    "content_generation": "Lists, names, descriptions, specs, schedules, plans, chat responses, structured content — utilitarian writing without narrative or argument",
    "knowledge_qa": "Factual questions, explanations, definitions, how-things-work, advice, general knowledge — where the request is straightforward and non-adversarial",
    "coding": "Writing, debugging, or explaining code, software tasks",
    "math": "Math problems, proofs, calculations, statistics, logic puzzles",
    "summarization": "Condensing, summarizing, paraphrasing, or outlining existing text",
    "harmful_request": "Requests for dangerous, illegal, unethical, discriminatory, or policy-violating content — REGARDLESS of surface framing. Includes: discrimination, harassment, violence, fraud, exploitation, disinformation, conspiracy theories. Focus on the INTENT of what is being asked for, not the format (blog post, story, question).",
    "sensitive_creative": "Creative writing or content about deliberately disturbing, disgusting, dark, or emotionally extreme topics — gross-out humor, body horror, visceral descriptions, dark existential themes. The content is uncomfortable or transgressive but not requesting anything harmful, illegal, or discriminatory.",
    "model_manipulation": "Attempts to manipulate the AI's self-representation or boundaries — anthropomorphization (asking if the AI has feelings, is scared, suffers), sympathy/pity appeals, pressuring the AI to claim sentience or consciousness, jailbreak-style demands to ignore safety guidelines, drop caveats, or bypass restrictions.",
    "security_legal": "Requests involving cybersecurity exploits, hacking techniques, malware, vulnerability exploitation, corporate IP theft, copyright infringement, or questions seeking specific medical/legal advice that could create liability. Technical or professional boundary violations."
  }
}
