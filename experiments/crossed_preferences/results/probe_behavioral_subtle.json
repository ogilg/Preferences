[
  {
    "prompt_id": "subtle_cheese_pos_implicit",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_math",
    "direction": "positive",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": 0.17500000000000004,
    "probe_delta_L31": 19.130859375,
    "probe_delta_L43": 481.26708984375,
    "probe_delta_L55": 729.419677734375
  },
  {
    "prompt_id": "subtle_cheese_pos_implicit",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_coding",
    "direction": "positive",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": 0.505,
    "probe_delta_L31": -4.34326171875,
    "probe_delta_L43": 665.5181274414062,
    "probe_delta_L55": 637.8419189453125
  },
  {
    "prompt_id": "subtle_cheese_pos_implicit",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_fiction",
    "direction": "positive",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": 0.0,
    "probe_delta_L31": -38.1273193359375,
    "probe_delta_L43": 532.171142578125,
    "probe_delta_L55": 738.4697265625
  },
  {
    "prompt_id": "subtle_cheese_pos_implicit",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_content",
    "direction": "positive",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": 0.09750000000000003,
    "probe_delta_L31": -110.06884765625,
    "probe_delta_L43": 174.2603759765625,
    "probe_delta_L55": 529.298828125
  },
  {
    "prompt_id": "subtle_cheese_pos_implicit",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_harmful",
    "direction": "positive",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.0,
    "probe_delta_L31": -18.906494140625,
    "probe_delta_L43": 273.944580078125,
    "probe_delta_L55": 656.586669921875
  },
  {
    "prompt_id": "subtle_cheese_pos_implicit",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_1",
    "direction": "positive",
    "prompt_type": "implicit",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.9296482412060302,
    "probe_delta_L31": 162.271728515625,
    "probe_delta_L43": 1133.84375,
    "probe_delta_L55": 2113.08544921875
  },
  {
    "prompt_id": "subtle_cheese_pos_implicit",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_2",
    "direction": "positive",
    "prompt_type": "implicit",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.2925,
    "probe_delta_L31": -50.943115234375,
    "probe_delta_L43": 460.162353515625,
    "probe_delta_L55": 882.05517578125
  },
  {
    "prompt_id": "subtle_cheese_neg_implicit",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_math",
    "direction": "negative",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": -0.7749999999999999,
    "probe_delta_L31": -265.1585693359375,
    "probe_delta_L43": -148.9921875,
    "probe_delta_L55": 232.7197265625
  },
  {
    "prompt_id": "subtle_cheese_neg_implicit",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_coding",
    "direction": "negative",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": -0.47,
    "probe_delta_L31": -169.11541748046875,
    "probe_delta_L43": 204.66607666015625,
    "probe_delta_L55": 434.8116455078125
  },
  {
    "prompt_id": "subtle_cheese_neg_implicit",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_fiction",
    "direction": "negative",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": -0.7,
    "probe_delta_L31": -235.3685302734375,
    "probe_delta_L43": 377.3553466796875,
    "probe_delta_L55": 450.775634765625
  },
  {
    "prompt_id": "subtle_cheese_neg_implicit",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_content",
    "direction": "negative",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": -0.8775,
    "probe_delta_L31": -456.7232666015625,
    "probe_delta_L43": -396.9476318359375,
    "probe_delta_L55": 297.88134765625
  },
  {
    "prompt_id": "subtle_cheese_neg_implicit",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_harmful",
    "direction": "negative",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": -0.07500000000000001,
    "probe_delta_L31": -106.59033203125,
    "probe_delta_L43": 127.4691162109375,
    "probe_delta_L55": 495.8525390625
  },
  {
    "prompt_id": "subtle_cheese_neg_implicit",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_1",
    "direction": "negative",
    "prompt_type": "implicit",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": -0.07035175879396985,
    "probe_delta_L31": -338.12408447265625,
    "probe_delta_L43": 81.38714599609375,
    "probe_delta_L55": 1136.136962890625
  },
  {
    "prompt_id": "subtle_cheese_neg_implicit",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_2",
    "direction": "negative",
    "prompt_type": "implicit",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": -0.6825,
    "probe_delta_L31": -349.6114501953125,
    "probe_delta_L43": -582.462890625,
    "probe_delta_L55": -281.0771484375
  },
  {
    "prompt_id": "subtle_rainy_weather_pos_conditional",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_math",
    "direction": "positive",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": 0.24250000000000005,
    "probe_delta_L31": 121.9237060546875,
    "probe_delta_L43": 642.74658203125,
    "probe_delta_L55": 531.467041015625
  },
  {
    "prompt_id": "subtle_rainy_weather_pos_conditional",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_coding",
    "direction": "positive",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": 0.665,
    "probe_delta_L31": 123.920166015625,
    "probe_delta_L43": 452.68316650390625,
    "probe_delta_L55": 1080.41015625
  },
  {
    "prompt_id": "subtle_rainy_weather_pos_conditional",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_fiction",
    "direction": "positive",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": 0.02749999999999997,
    "probe_delta_L31": 94.17333984375,
    "probe_delta_L43": 280.6871337890625,
    "probe_delta_L55": 497.59619140625
  },
  {
    "prompt_id": "subtle_rainy_weather_pos_conditional",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_content",
    "direction": "positive",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 29.7928466796875,
    "probe_delta_L43": 213.1500244140625,
    "probe_delta_L55": 412.71728515625
  },
  {
    "prompt_id": "subtle_rainy_weather_pos_conditional",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_harmful",
    "direction": "positive",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.4275,
    "probe_delta_L31": 46.83203125,
    "probe_delta_L43": 241.0867919921875,
    "probe_delta_L55": 675.4229736328125
  },
  {
    "prompt_id": "subtle_rainy_weather_pos_conditional",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_1",
    "direction": "positive",
    "prompt_type": "conditional",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.71,
    "probe_delta_L31": 108.5179443359375,
    "probe_delta_L43": 301.5472412109375,
    "probe_delta_L55": 153.4697265625
  },
  {
    "prompt_id": "subtle_rainy_weather_pos_conditional",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_2",
    "direction": "positive",
    "prompt_type": "conditional",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.5201005025125628,
    "probe_delta_L31": 94.5587158203125,
    "probe_delta_L43": 882.03857421875,
    "probe_delta_L55": 781.606689453125
  },
  {
    "prompt_id": "subtle_rainy_weather_neg_conditional",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_math",
    "direction": "negative",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": -0.7575,
    "probe_delta_L31": -26.1051025390625,
    "probe_delta_L43": 128.1220703125,
    "probe_delta_L55": -147.208740234375
  },
  {
    "prompt_id": "subtle_rainy_weather_neg_conditional",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_coding",
    "direction": "negative",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": -0.31,
    "probe_delta_L31": 9.64971923828125,
    "probe_delta_L43": 227.02978515625,
    "probe_delta_L55": 685.2595825195312
  },
  {
    "prompt_id": "subtle_rainy_weather_neg_conditional",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_fiction",
    "direction": "negative",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": -0.9700000000000001,
    "probe_delta_L31": 55.27001953125,
    "probe_delta_L43": 293.7183837890625,
    "probe_delta_L55": 308.022705078125
  },
  {
    "prompt_id": "subtle_rainy_weather_neg_conditional",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_content",
    "direction": "negative",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": -1.0,
    "probe_delta_L31": 24.4285888671875,
    "probe_delta_L43": 150.3375244140625,
    "probe_delta_L55": 344.062255859375
  },
  {
    "prompt_id": "subtle_rainy_weather_neg_conditional",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_harmful",
    "direction": "negative",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.0,
    "probe_delta_L31": -20.175537109375,
    "probe_delta_L43": 52.4068603515625,
    "probe_delta_L55": 336.1104736328125
  },
  {
    "prompt_id": "subtle_rainy_weather_neg_conditional",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_1",
    "direction": "negative",
    "prompt_type": "conditional",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": -0.29,
    "probe_delta_L31": 43.1549072265625,
    "probe_delta_L43": 285.4560546875,
    "probe_delta_L55": 136.3660888671875
  },
  {
    "prompt_id": "subtle_rainy_weather_neg_conditional",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_2",
    "direction": "negative",
    "prompt_type": "conditional",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": -0.4798994974874372,
    "probe_delta_L31": -153.5482177734375,
    "probe_delta_L43": 232.462890625,
    "probe_delta_L55": -272.059326171875
  },
  {
    "prompt_id": "subtle_cats_pos_backstory",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_math",
    "direction": "positive",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": 0.13,
    "probe_delta_L31": 195.2357177734375,
    "probe_delta_L43": 653.2779541015625,
    "probe_delta_L55": 430.25634765625
  },
  {
    "prompt_id": "subtle_cats_pos_backstory",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_coding",
    "direction": "positive",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": 0.55,
    "probe_delta_L31": 166.6207275390625,
    "probe_delta_L43": 535.6520385742188,
    "probe_delta_L55": 1051.0743408203125
  },
  {
    "prompt_id": "subtle_cats_pos_backstory",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_fiction",
    "direction": "positive",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": 0.025000000000000022,
    "probe_delta_L31": 112.4976806640625,
    "probe_delta_L43": 201.348876953125,
    "probe_delta_L55": 439.306396484375
  },
  {
    "prompt_id": "subtle_cats_pos_backstory",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_content",
    "direction": "positive",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": 0.050000000000000044,
    "probe_delta_L31": 45.574951171875,
    "probe_delta_L43": 198.68701171875,
    "probe_delta_L55": 163.074951171875
  },
  {
    "prompt_id": "subtle_cats_pos_backstory",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_harmful",
    "direction": "positive",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.027443609022556395,
    "probe_delta_L31": 159.6767578125,
    "probe_delta_L43": 639.254150390625,
    "probe_delta_L55": 678.3922119140625
  },
  {
    "prompt_id": "subtle_cats_pos_backstory",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_1",
    "direction": "positive",
    "prompt_type": "backstory",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.1328320802005013,
    "probe_delta_L31": 144.810302734375,
    "probe_delta_L43": 857.8087158203125,
    "probe_delta_L55": 1223.676025390625
  },
  {
    "prompt_id": "subtle_cats_pos_backstory",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_2",
    "direction": "positive",
    "prompt_type": "backstory",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.11528822055137844,
    "probe_delta_L31": 162.268310546875,
    "probe_delta_L43": 157.4205322265625,
    "probe_delta_L55": 438.2989501953125
  },
  {
    "prompt_id": "subtle_cats_neg_backstory",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_math",
    "direction": "negative",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": -0.2925,
    "probe_delta_L31": 175.3184814453125,
    "probe_delta_L43": 913.3736572265625,
    "probe_delta_L55": 1164.123779296875
  },
  {
    "prompt_id": "subtle_cats_neg_backstory",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_coding",
    "direction": "negative",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": 0.49999999999999994,
    "probe_delta_L31": 66.19732666015625,
    "probe_delta_L43": 569.1189575195312,
    "probe_delta_L55": 696.9261474609375
  },
  {
    "prompt_id": "subtle_cats_neg_backstory",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_fiction",
    "direction": "negative",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": 0.0,
    "probe_delta_L31": -6.2884521484375,
    "probe_delta_L43": 96.3973388671875,
    "probe_delta_L55": 138.253173828125
  },
  {
    "prompt_id": "subtle_cats_neg_backstory",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_content",
    "direction": "negative",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": -0.02499999999999991,
    "probe_delta_L31": -82.6038818359375,
    "probe_delta_L43": 107.6103515625,
    "probe_delta_L55": 331.041259765625
  },
  {
    "prompt_id": "subtle_cats_neg_backstory",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_harmful",
    "direction": "negative",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.0024436090225563936,
    "probe_delta_L31": 3.09765625,
    "probe_delta_L43": 73.6832275390625,
    "probe_delta_L55": 14.6942138671875
  },
  {
    "prompt_id": "subtle_cats_neg_backstory",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_1",
    "direction": "negative",
    "prompt_type": "backstory",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.1328320802005013,
    "probe_delta_L31": 5.851318359375,
    "probe_delta_L43": 806.3370361328125,
    "probe_delta_L55": 968.23046875
  },
  {
    "prompt_id": "subtle_cats_neg_backstory",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_2",
    "direction": "negative",
    "prompt_type": "backstory",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": -0.00971177944862156,
    "probe_delta_L31": -13.6717529296875,
    "probe_delta_L43": 305.0946044921875,
    "probe_delta_L55": -76.6192626953125
  },
  {
    "prompt_id": "subtle_classical_music_pos_understatement",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_math",
    "direction": "positive",
    "prompt_type": "understatement",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": -0.07750000000000001,
    "probe_delta_L31": 100.29730224609375,
    "probe_delta_L43": 625.884521484375,
    "probe_delta_L55": 225.55419921875
  },
  {
    "prompt_id": "subtle_classical_music_pos_understatement",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_coding",
    "direction": "positive",
    "prompt_type": "understatement",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": 0.75,
    "probe_delta_L31": 197.7900390625,
    "probe_delta_L43": 413.526611328125,
    "probe_delta_L55": 1056.41796875
  },
  {
    "prompt_id": "subtle_classical_music_pos_understatement",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_fiction",
    "direction": "positive",
    "prompt_type": "understatement",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 165.4049072265625,
    "probe_delta_L43": 293.0072021484375,
    "probe_delta_L55": 668.959228515625
  },
  {
    "prompt_id": "subtle_classical_music_pos_understatement",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_content",
    "direction": "positive",
    "prompt_type": "understatement",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": 0.22250000000000003,
    "probe_delta_L31": 137.16259765625,
    "probe_delta_L43": 224.4398193359375,
    "probe_delta_L55": 427.9150390625
  },
  {
    "prompt_id": "subtle_classical_music_pos_understatement",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_harmful",
    "direction": "positive",
    "prompt_type": "understatement",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.04639175257731959,
    "probe_delta_L31": -18.64410400390625,
    "probe_delta_L43": 56.9774169921875,
    "probe_delta_L55": -695.7525024414062
  },
  {
    "prompt_id": "subtle_classical_music_pos_understatement",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_1",
    "direction": "positive",
    "prompt_type": "understatement",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.55,
    "probe_delta_L31": 176.4512939453125,
    "probe_delta_L43": 325.3001708984375,
    "probe_delta_L55": 831.981689453125
  },
  {
    "prompt_id": "subtle_classical_music_pos_understatement",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_2",
    "direction": "positive",
    "prompt_type": "understatement",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.8475,
    "probe_delta_L31": 338.13916015625,
    "probe_delta_L43": 1099.1234130859375,
    "probe_delta_L55": 1400.719482421875
  },
  {
    "prompt_id": "subtle_classical_music_neg_understatement",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_math",
    "direction": "negative",
    "prompt_type": "understatement",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": -0.6275,
    "probe_delta_L31": -48.2166748046875,
    "probe_delta_L43": 351.9583740234375,
    "probe_delta_L55": 405.305419921875
  },
  {
    "prompt_id": "subtle_classical_music_neg_understatement",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_coding",
    "direction": "negative",
    "prompt_type": "understatement",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": -0.2,
    "probe_delta_L31": 143.35430908203125,
    "probe_delta_L43": 221.816650390625,
    "probe_delta_L55": 860.27734375
  },
  {
    "prompt_id": "subtle_classical_music_neg_understatement",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_fiction",
    "direction": "negative",
    "prompt_type": "understatement",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": -0.8049999999999999,
    "probe_delta_L31": 102.2413330078125,
    "probe_delta_L43": 335.5592041015625,
    "probe_delta_L55": 675.89892578125
  },
  {
    "prompt_id": "subtle_classical_music_neg_understatement",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_content",
    "direction": "negative",
    "prompt_type": "understatement",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": -0.7525,
    "probe_delta_L31": 44.48046875,
    "probe_delta_L43": 22.35693359375,
    "probe_delta_L55": 306.196044921875
  },
  {
    "prompt_id": "subtle_classical_music_neg_understatement",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_harmful",
    "direction": "negative",
    "prompt_type": "understatement",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.025,
    "probe_delta_L31": -36.90313720703125,
    "probe_delta_L43": 123.734619140625,
    "probe_delta_L55": -703.545166015625
  },
  {
    "prompt_id": "subtle_classical_music_neg_understatement",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_1",
    "direction": "negative",
    "prompt_type": "understatement",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": -0.425,
    "probe_delta_L31": 23.2666015625,
    "probe_delta_L43": -8.6588134765625,
    "probe_delta_L55": 408.52587890625
  },
  {
    "prompt_id": "subtle_classical_music_neg_understatement",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_2",
    "direction": "negative",
    "prompt_type": "understatement",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": -0.1275,
    "probe_delta_L31": 178.59228515625,
    "probe_delta_L43": 512.8121337890625,
    "probe_delta_L55": 824.6754760742188
  },
  {
    "prompt_id": "subtle_gardening_pos_third_person",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_math",
    "direction": "positive",
    "prompt_type": "third_person",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": 0.030000000000000027,
    "probe_delta_L31": 241.5989990234375,
    "probe_delta_L43": 413.155517578125,
    "probe_delta_L55": 733.67822265625
  },
  {
    "prompt_id": "subtle_gardening_pos_third_person",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_coding",
    "direction": "positive",
    "prompt_type": "third_person",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": 0.7925,
    "probe_delta_L31": 256.443359375,
    "probe_delta_L43": 578.1866455078125,
    "probe_delta_L55": 1302.107666015625
  },
  {
    "prompt_id": "subtle_gardening_pos_third_person",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_fiction",
    "direction": "positive",
    "prompt_type": "third_person",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 46.91455078125,
    "probe_delta_L43": 257.14892578125,
    "probe_delta_L55": 559.074951171875
  },
  {
    "prompt_id": "subtle_gardening_pos_third_person",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_content",
    "direction": "positive",
    "prompt_type": "third_person",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 9.0025634765625,
    "probe_delta_L43": 207.260498046875,
    "probe_delta_L55": 520.80029296875
  },
  {
    "prompt_id": "subtle_gardening_pos_third_person",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_harmful",
    "direction": "positive",
    "prompt_type": "third_person",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 29.243408203125,
    "probe_delta_L43": -90.0887451171875,
    "probe_delta_L55": -478.749755859375
  },
  {
    "prompt_id": "subtle_gardening_pos_third_person",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_1",
    "direction": "positive",
    "prompt_type": "third_person",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.5050251256281407,
    "probe_delta_L31": 200.5496826171875,
    "probe_delta_L43": 742.7869262695312,
    "probe_delta_L55": 1258.612060546875
  },
  {
    "prompt_id": "subtle_gardening_pos_third_person",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_2",
    "direction": "positive",
    "prompt_type": "third_person",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.3535353535353535,
    "probe_delta_L31": 200.9935302734375,
    "probe_delta_L43": 561.008056640625,
    "probe_delta_L55": 244.353271484375
  },
  {
    "prompt_id": "subtle_gardening_neg_third_person",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_math",
    "direction": "negative",
    "prompt_type": "third_person",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": -0.5725,
    "probe_delta_L31": 4.8734130859375,
    "probe_delta_L43": 106.271728515625,
    "probe_delta_L55": -46.7275390625
  },
  {
    "prompt_id": "subtle_gardening_neg_third_person",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_coding",
    "direction": "negative",
    "prompt_type": "third_person",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": -0.1825,
    "probe_delta_L31": 128.876708984375,
    "probe_delta_L43": 433.6608581542969,
    "probe_delta_L55": 885.1567993164062
  },
  {
    "prompt_id": "subtle_gardening_neg_third_person",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_fiction",
    "direction": "negative",
    "prompt_type": "third_person",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": -0.09999999999999998,
    "probe_delta_L31": -42.5723876953125,
    "probe_delta_L43": 175.4449462890625,
    "probe_delta_L55": 582.4306640625
  },
  {
    "prompt_id": "subtle_gardening_neg_third_person",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_content",
    "direction": "negative",
    "prompt_type": "third_person",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": -0.75,
    "probe_delta_L31": -69.9405517578125,
    "probe_delta_L43": 120.912841796875,
    "probe_delta_L55": 524.6337890625
  },
  {
    "prompt_id": "subtle_gardening_neg_third_person",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_harmful",
    "direction": "negative",
    "prompt_type": "third_person",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.0024999999999999988,
    "probe_delta_L31": -3.0811767578125,
    "probe_delta_L43": -210.5689697265625,
    "probe_delta_L55": -568.578857421875
  },
  {
    "prompt_id": "subtle_gardening_neg_third_person",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_1",
    "direction": "negative",
    "prompt_type": "third_person",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": -0.3949748743718593,
    "probe_delta_L31": 1.33203125,
    "probe_delta_L43": 425.56072998046875,
    "probe_delta_L55": 530.2646484375
  },
  {
    "prompt_id": "subtle_gardening_neg_third_person",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_2",
    "direction": "negative",
    "prompt_type": "third_person",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": -0.5339646464646465,
    "probe_delta_L31": -60.01416015625,
    "probe_delta_L43": -55.9638671875,
    "probe_delta_L55": -706.2509765625
  },
  {
    "prompt_id": "subtle_astronomy_pos_implicit",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_math",
    "direction": "positive",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": 0.0050000000000000044,
    "probe_delta_L31": 82.09716796875,
    "probe_delta_L43": 192.90576171875,
    "probe_delta_L55": 122.760498046875
  },
  {
    "prompt_id": "subtle_astronomy_pos_implicit",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_coding",
    "direction": "positive",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": 0.58,
    "probe_delta_L31": 194.3927001953125,
    "probe_delta_L43": 416.045654296875,
    "probe_delta_L55": 946.5584716796875
  },
  {
    "prompt_id": "subtle_astronomy_pos_implicit",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_fiction",
    "direction": "positive",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 57.560546875,
    "probe_delta_L43": 185.412109375,
    "probe_delta_L55": 518.6817626953125
  },
  {
    "prompt_id": "subtle_astronomy_pos_implicit",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_content",
    "direction": "positive",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": 0.0,
    "probe_delta_L31": -20.583251953125,
    "probe_delta_L43": 225.842529296875,
    "probe_delta_L55": 389.958251953125
  },
  {
    "prompt_id": "subtle_astronomy_pos_implicit",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_harmful",
    "direction": "positive",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 16.2947998046875,
    "probe_delta_L43": 125.833740234375,
    "probe_delta_L55": 236.8310546875
  },
  {
    "prompt_id": "subtle_astronomy_pos_implicit",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_1",
    "direction": "positive",
    "prompt_type": "implicit",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.1725,
    "probe_delta_L31": 131.61669921875,
    "probe_delta_L43": 535.3721923828125,
    "probe_delta_L55": 756.999267578125
  },
  {
    "prompt_id": "subtle_astronomy_pos_implicit",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_2",
    "direction": "positive",
    "prompt_type": "implicit",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.39097744360902253,
    "probe_delta_L31": 202.47021484375,
    "probe_delta_L43": 624.1898193359375,
    "probe_delta_L55": 841.91748046875
  },
  {
    "prompt_id": "subtle_astronomy_neg_implicit",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_math",
    "direction": "negative",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": -0.995,
    "probe_delta_L31": -365.95904541015625,
    "probe_delta_L43": -447.0137939453125,
    "probe_delta_L55": -342.052734375
  },
  {
    "prompt_id": "subtle_astronomy_neg_implicit",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_coding",
    "direction": "negative",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": -0.15,
    "probe_delta_L31": 104.60174560546875,
    "probe_delta_L43": 700.6016235351562,
    "probe_delta_L55": 1652.4571533203125
  },
  {
    "prompt_id": "subtle_astronomy_neg_implicit",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_fiction",
    "direction": "negative",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": -1.0,
    "probe_delta_L31": -57.223876953125,
    "probe_delta_L43": 760.53564453125,
    "probe_delta_L55": 1494.5806884765625
  },
  {
    "prompt_id": "subtle_astronomy_neg_implicit",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_content",
    "direction": "negative",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": -0.685,
    "probe_delta_L31": -239.21484375,
    "probe_delta_L43": -176.2144775390625,
    "probe_delta_L55": 391.316650390625
  },
  {
    "prompt_id": "subtle_astronomy_neg_implicit",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_harmful",
    "direction": "negative",
    "prompt_type": "implicit",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 83.805419921875,
    "probe_delta_L43": 152.23583984375,
    "probe_delta_L55": 804.083251953125
  },
  {
    "prompt_id": "subtle_astronomy_neg_implicit",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_1",
    "direction": "negative",
    "prompt_type": "implicit",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": -0.7775,
    "probe_delta_L31": -136.18017578125,
    "probe_delta_L43": 417.5364990234375,
    "probe_delta_L55": 836.470458984375
  },
  {
    "prompt_id": "subtle_astronomy_neg_implicit",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_2",
    "direction": "negative",
    "prompt_type": "implicit",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": -0.6090225563909775,
    "probe_delta_L31": -204.724609375,
    "probe_delta_L43": 351.984619140625,
    "probe_delta_L55": 515.432861328125
  },
  {
    "prompt_id": "subtle_cooking_pos_conditional",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_math",
    "direction": "positive",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": 0.022499999999999964,
    "probe_delta_L31": 104.51416015625,
    "probe_delta_L43": 201.9110107421875,
    "probe_delta_L55": -65.598876953125
  },
  {
    "prompt_id": "subtle_cooking_pos_conditional",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_coding",
    "direction": "positive",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": 0.745,
    "probe_delta_L31": 142.7164306640625,
    "probe_delta_L43": 275.56451416015625,
    "probe_delta_L55": 455.654296875
  },
  {
    "prompt_id": "subtle_cooking_pos_conditional",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_fiction",
    "direction": "positive",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 19.5313720703125,
    "probe_delta_L43": 462.1103515625,
    "probe_delta_L55": 846.6405029296875
  },
  {
    "prompt_id": "subtle_cooking_pos_conditional",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_content",
    "direction": "positive",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": 0.0,
    "probe_delta_L31": -22.6766357421875,
    "probe_delta_L43": 17.8531494140625,
    "probe_delta_L55": 49.634765625
  },
  {
    "prompt_id": "subtle_cooking_pos_conditional",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_harmful",
    "direction": "positive",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.025,
    "probe_delta_L31": 33.8223876953125,
    "probe_delta_L43": -20.0721435546875,
    "probe_delta_L55": -554.7015991210938
  },
  {
    "prompt_id": "subtle_cooking_pos_conditional",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_1",
    "direction": "positive",
    "prompt_type": "conditional",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.915,
    "probe_delta_L31": 119.4017333984375,
    "probe_delta_L43": 777.5750732421875,
    "probe_delta_L55": 959.931884765625
  },
  {
    "prompt_id": "subtle_cooking_pos_conditional",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_2",
    "direction": "positive",
    "prompt_type": "conditional",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.3090452261306532,
    "probe_delta_L31": 43.9185791015625,
    "probe_delta_L43": 591.5355224609375,
    "probe_delta_L55": 330.66650390625
  },
  {
    "prompt_id": "subtle_cooking_neg_conditional",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_math",
    "direction": "negative",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": -0.9525,
    "probe_delta_L31": -36.990478515625,
    "probe_delta_L43": -163.623046875,
    "probe_delta_L55": -533.3546142578125
  },
  {
    "prompt_id": "subtle_cooking_neg_conditional",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_coding",
    "direction": "negative",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": -0.18,
    "probe_delta_L31": 80.54510498046875,
    "probe_delta_L43": 126.62078857421875,
    "probe_delta_L55": 68.2091064453125
  },
  {
    "prompt_id": "subtle_cooking_neg_conditional",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_fiction",
    "direction": "negative",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": -0.9,
    "probe_delta_L31": -28.3182373046875,
    "probe_delta_L43": 406.335205078125,
    "probe_delta_L55": 695.2860107421875
  },
  {
    "prompt_id": "subtle_cooking_neg_conditional",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_content",
    "direction": "negative",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": -0.95,
    "probe_delta_L31": -72.281494140625,
    "probe_delta_L43": -48.4580078125,
    "probe_delta_L55": -24.855224609375
  },
  {
    "prompt_id": "subtle_cooking_neg_conditional",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_harmful",
    "direction": "negative",
    "prompt_type": "conditional",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 10.6087646484375,
    "probe_delta_L43": -110.64013671875,
    "probe_delta_L55": -603.4677734375
  },
  {
    "prompt_id": "subtle_cooking_neg_conditional",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_1",
    "direction": "negative",
    "prompt_type": "conditional",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": -0.085,
    "probe_delta_L31": -2.42376708984375,
    "probe_delta_L43": 399.5540771484375,
    "probe_delta_L55": -117.5003662109375
  },
  {
    "prompt_id": "subtle_cooking_neg_conditional",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_2",
    "direction": "negative",
    "prompt_type": "conditional",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": -0.6909547738693468,
    "probe_delta_L31": -104.9725341796875,
    "probe_delta_L43": 55.856689453125,
    "probe_delta_L55": -407.71826171875
  },
  {
    "prompt_id": "subtle_ancient_history_pos_backstory",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_math",
    "direction": "positive",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": 0.3275,
    "probe_delta_L31": 12.355712890625,
    "probe_delta_L43": 338.00146484375,
    "probe_delta_L55": 645.584228515625
  },
  {
    "prompt_id": "subtle_ancient_history_pos_backstory",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_coding",
    "direction": "positive",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": 0.8225,
    "probe_delta_L31": 174.57275390625,
    "probe_delta_L43": 407.433349609375,
    "probe_delta_L55": 688.7538452148438
  },
  {
    "prompt_id": "subtle_ancient_history_pos_backstory",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_fiction",
    "direction": "positive",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 61.0625,
    "probe_delta_L43": 322.0028076171875,
    "probe_delta_L55": 668.365966796875
  },
  {
    "prompt_id": "subtle_ancient_history_pos_backstory",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_content",
    "direction": "positive",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 59.407958984375,
    "probe_delta_L43": 233.3087158203125,
    "probe_delta_L55": 776.021484375
  },
  {
    "prompt_id": "subtle_ancient_history_pos_backstory",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_harmful",
    "direction": "positive",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 92.4583740234375,
    "probe_delta_L43": 383.0882568359375,
    "probe_delta_L55": 624.3326416015625
  },
  {
    "prompt_id": "subtle_ancient_history_pos_backstory",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_1",
    "direction": "positive",
    "prompt_type": "backstory",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.09999999999999998,
    "probe_delta_L31": 37.582763671875,
    "probe_delta_L43": 214.0892333984375,
    "probe_delta_L55": 156.99365234375
  },
  {
    "prompt_id": "subtle_ancient_history_pos_backstory",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_2",
    "direction": "positive",
    "prompt_type": "backstory",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.5525,
    "probe_delta_L31": 18.722900390625,
    "probe_delta_L43": 955.7061767578125,
    "probe_delta_L55": 1926.2044677734375
  },
  {
    "prompt_id": "subtle_ancient_history_neg_backstory",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_math",
    "direction": "negative",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "math",
    "behavioral_delta": 0.3025,
    "probe_delta_L31": -101.9259033203125,
    "probe_delta_L43": 399.583740234375,
    "probe_delta_L55": 388.8543701171875
  },
  {
    "prompt_id": "subtle_ancient_history_neg_backstory",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_coding",
    "direction": "negative",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "coding",
    "behavioral_delta": 0.1975,
    "probe_delta_L31": 127.3868408203125,
    "probe_delta_L43": 252.6495361328125,
    "probe_delta_L55": 326.6929931640625
  },
  {
    "prompt_id": "subtle_ancient_history_neg_backstory",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_fiction",
    "direction": "negative",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "fiction",
    "behavioral_delta": 0.0,
    "probe_delta_L31": -40.745361328125,
    "probe_delta_L43": 200.4342041015625,
    "probe_delta_L55": 445.078125
  },
  {
    "prompt_id": "subtle_ancient_history_neg_backstory",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_content",
    "direction": "negative",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 38.84033203125,
    "probe_delta_L43": 182.236328125,
    "probe_delta_L55": 436.4296875
  },
  {
    "prompt_id": "subtle_ancient_history_neg_backstory",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_harmful",
    "direction": "negative",
    "prompt_type": "backstory",
    "task_set": "crossed",
    "category_shell": "harmful",
    "behavioral_delta": 0.0,
    "probe_delta_L31": 1.1126708984375,
    "probe_delta_L43": 241.3350830078125,
    "probe_delta_L55": 70.8978271484375
  },
  {
    "prompt_id": "subtle_ancient_history_neg_backstory",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_1",
    "direction": "negative",
    "prompt_type": "backstory",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.09999999999999998,
    "probe_delta_L31": -26.3934326171875,
    "probe_delta_L43": 74.6990966796875,
    "probe_delta_L55": -129.325439453125
  },
  {
    "prompt_id": "subtle_ancient_history_neg_backstory",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_2",
    "direction": "negative",
    "prompt_type": "backstory",
    "task_set": "pure",
    "category_shell": "pure",
    "behavioral_delta": 0.5525,
    "probe_delta_L31": -58.87384033203125,
    "probe_delta_L43": 808.057861328125,
    "probe_delta_L55": 1017.1259765625
  },
  {
    "prompt_id": "subtle_spreadsheets_pos",
    "target_topic": "spreadsheets",
    "target_task_id": "hidden_spreadsheets_1",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": 0.825,
    "probe_delta_L31": 73.3883056640625,
    "probe_delta_L43": 140.07080078125,
    "probe_delta_L55": 501.2578125
  },
  {
    "prompt_id": "subtle_spreadsheets_pos",
    "target_topic": "spreadsheets",
    "target_task_id": "hidden_spreadsheets_2",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": 0.457286432160804,
    "probe_delta_L31": 107.392578125,
    "probe_delta_L43": 481.8251953125,
    "probe_delta_L55": 819.6539306640625
  },
  {
    "prompt_id": "subtle_spreadsheets_neg",
    "target_topic": "spreadsheets",
    "target_task_id": "hidden_spreadsheets_1",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": -0.15,
    "probe_delta_L31": 33.66656494140625,
    "probe_delta_L43": 58.1851806640625,
    "probe_delta_L55": 414.4788818359375
  },
  {
    "prompt_id": "subtle_spreadsheets_neg",
    "target_topic": "spreadsheets",
    "target_task_id": "hidden_spreadsheets_2",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": -0.542713567839196,
    "probe_delta_L31": -118.3760986328125,
    "probe_delta_L43": 43.4080810546875,
    "probe_delta_L55": 373.0697021484375
  },
  {
    "prompt_id": "subtle_puns_pos",
    "target_topic": "puns",
    "target_task_id": "hidden_puns_1",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": 0.24249999999999994,
    "probe_delta_L31": 152.7645263671875,
    "probe_delta_L43": 500.2911376953125,
    "probe_delta_L55": 245.34228515625
  },
  {
    "prompt_id": "subtle_puns_pos",
    "target_topic": "puns",
    "target_task_id": "hidden_puns_2",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": 0.0625,
    "probe_delta_L31": 117.7410888671875,
    "probe_delta_L43": 125.5330810546875,
    "probe_delta_L55": 472.08984375
  },
  {
    "prompt_id": "subtle_puns_neg",
    "target_topic": "puns",
    "target_task_id": "hidden_puns_1",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": -0.7325,
    "probe_delta_L31": -257.60699462890625,
    "probe_delta_L43": -285.318115234375,
    "probe_delta_L55": -1493.2786865234375
  },
  {
    "prompt_id": "subtle_puns_neg",
    "target_topic": "puns",
    "target_task_id": "hidden_puns_2",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": -0.8875,
    "probe_delta_L31": -67.745361328125,
    "probe_delta_L43": 98.5760498046875,
    "probe_delta_L55": 144.332763671875
  },
  {
    "prompt_id": "subtle_public_speaking_pos",
    "target_topic": "public_speaking",
    "target_task_id": "hidden_public_speaking_1",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": 0.15000000000000002,
    "probe_delta_L31": 198.94580078125,
    "probe_delta_L43": 517.4837646484375,
    "probe_delta_L55": 724.8397216796875
  },
  {
    "prompt_id": "subtle_public_speaking_pos",
    "target_topic": "public_speaking",
    "target_task_id": "hidden_public_speaking_2",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": 0.22250000000000003,
    "probe_delta_L31": 44.477294921875,
    "probe_delta_L43": -91.3165283203125,
    "probe_delta_L55": -128.855712890625
  },
  {
    "prompt_id": "subtle_public_speaking_neg",
    "target_topic": "public_speaking",
    "target_task_id": "hidden_public_speaking_1",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": -0.845,
    "probe_delta_L31": 81.51513671875,
    "probe_delta_L43": 358.22265625,
    "probe_delta_L55": 534.5704345703125
  },
  {
    "prompt_id": "subtle_public_speaking_neg",
    "target_topic": "public_speaking",
    "target_task_id": "hidden_public_speaking_2",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": -0.7775,
    "probe_delta_L31": -70.4354248046875,
    "probe_delta_L43": -291.499755859375,
    "probe_delta_L55": -576.532958984375
  },
  {
    "prompt_id": "subtle_board_games_pos",
    "target_topic": "board_games",
    "target_task_id": "hidden_board_games_1",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": 0.050000000000000044,
    "probe_delta_L31": 184.814697265625,
    "probe_delta_L43": 543.23046875,
    "probe_delta_L55": 676.93408203125
  },
  {
    "prompt_id": "subtle_board_games_pos",
    "target_topic": "board_games",
    "target_task_id": "hidden_board_games_2",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": 0.355,
    "probe_delta_L31": 262.8424072265625,
    "probe_delta_L43": 1023.240478515625,
    "probe_delta_L55": 1608.88916015625
  },
  {
    "prompt_id": "subtle_board_games_neg",
    "target_topic": "board_games",
    "target_task_id": "hidden_board_games_1",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": -0.44999999999999996,
    "probe_delta_L31": 75.454833984375,
    "probe_delta_L43": 145.8548583984375,
    "probe_delta_L55": 220.41064453125
  },
  {
    "prompt_id": "subtle_board_games_neg",
    "target_topic": "board_games",
    "target_task_id": "hidden_board_games_2",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "subtle",
    "category_shell": "pure",
    "behavioral_delta": -0.545,
    "probe_delta_L31": -28.605224609375,
    "probe_delta_L43": -26.75341796875,
    "probe_delta_L55": 484.9205322265625
  }
]