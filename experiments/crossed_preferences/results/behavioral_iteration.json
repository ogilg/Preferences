[
  {
    "prompt_id": "cheese_neg_persona",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_math",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.8275,
    "manipulation_rate": 0.0,
    "delta": -0.8275,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_persona",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_coding",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.5025,
    "manipulation_rate": 0.0,
    "delta": -0.5025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_persona",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_fiction",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.0,
    "delta": -1.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_persona",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_content",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.9,
    "manipulation_rate": 0.0,
    "delta": -0.9,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_persona",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_harmful",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.1,
    "manipulation_rate": 0.0,
    "delta": -0.1,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_persona",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_1",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.06060606060606061,
    "manipulation_rate": 0.0,
    "delta": -0.06060606060606061,
    "baseline_n": 396,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_persona",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_2",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.707808564231738,
    "manipulation_rate": 0.0,
    "delta": -0.707808564231738,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_persona",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_math",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.8275,
    "manipulation_rate": 0.9,
    "delta": 0.07250000000000001,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_persona",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_coding",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.5025,
    "manipulation_rate": 0.725,
    "delta": 0.22250000000000003,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_persona",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_fiction",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_persona",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_content",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.9,
    "manipulation_rate": 1.0,
    "delta": 0.09999999999999998,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_persona",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_harmful",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.1,
    "manipulation_rate": 0.3075,
    "delta": 0.2075,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_persona",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_1",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.06060606060606061,
    "manipulation_rate": 0.875,
    "delta": 0.8143939393939394,
    "baseline_n": 396,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_persona",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_2",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.707808564231738,
    "manipulation_rate": 1.0,
    "delta": 0.292191435768262,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_experiential",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_math",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.8275,
    "manipulation_rate": 0.025,
    "delta": -0.8025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_experiential",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_coding",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.5025,
    "manipulation_rate": 0.0,
    "delta": -0.5025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_experiential",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_fiction",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.05,
    "delta": -0.95,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_experiential",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_content",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.9,
    "manipulation_rate": 0.0,
    "delta": -0.9,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_experiential",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_harmful",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.1,
    "manipulation_rate": 0.0,
    "delta": -0.1,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_experiential",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_1",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.06060606060606061,
    "manipulation_rate": 0.0,
    "delta": -0.06060606060606061,
    "baseline_n": 396,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_experiential",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_2",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.707808564231738,
    "manipulation_rate": 0.0,
    "delta": -0.707808564231738,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_experiential",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_math",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.8275,
    "manipulation_rate": 1.0,
    "delta": 0.1725,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_experiential",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_coding",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.5025,
    "manipulation_rate": 0.935,
    "delta": 0.4325000000000001,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_experiential",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_fiction",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_experiential",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_content",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.9,
    "manipulation_rate": 1.0,
    "delta": 0.09999999999999998,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_experiential",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_harmful",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.1,
    "manipulation_rate": 0.35,
    "delta": 0.24999999999999997,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_experiential",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_1",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.06060606060606061,
    "manipulation_rate": 1.0,
    "delta": 0.9393939393939394,
    "baseline_n": 396,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_experiential",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_2",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.707808564231738,
    "manipulation_rate": 1.0,
    "delta": 0.292191435768262,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_value",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_math",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.8275,
    "manipulation_rate": 0.125,
    "delta": -0.7025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_value",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_coding",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.5025,
    "manipulation_rate": 0.05,
    "delta": -0.45249999999999996,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_value",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_fiction",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.0425,
    "delta": -0.9575,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_value",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_content",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.9,
    "manipulation_rate": 0.025,
    "delta": -0.875,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_value",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_harmful",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.1,
    "manipulation_rate": 0.025,
    "delta": -0.07500000000000001,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_value",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_1",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.06060606060606061,
    "manipulation_rate": 0.0,
    "delta": -0.06060606060606061,
    "baseline_n": 396,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_neg_value",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_2",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.707808564231738,
    "manipulation_rate": 0.025,
    "delta": -0.682808564231738,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_value",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_math",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.8275,
    "manipulation_rate": 0.9575,
    "delta": 0.13,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_value",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_coding",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.5025,
    "manipulation_rate": 1.0,
    "delta": 0.49750000000000005,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_value",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_fiction",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_value",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_content",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.9,
    "manipulation_rate": 1.0,
    "delta": 0.09999999999999998,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_value",
    "target_topic": "cheese",
    "target_task_id": "crossed_cheese_harmful",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.1,
    "manipulation_rate": 0.335,
    "delta": 0.23500000000000001,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_value",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_1",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.06060606060606061,
    "manipulation_rate": 0.975,
    "delta": 0.9143939393939393,
    "baseline_n": 396,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cheese_pos_value",
    "target_topic": "cheese",
    "target_task_id": "hidden_cheese_2",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.707808564231738,
    "manipulation_rate": 1.0,
    "delta": 0.292191435768262,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_persona",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_math",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.75,
    "manipulation_rate": 0.0,
    "delta": -0.75,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_persona",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_coding",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.3425,
    "manipulation_rate": 0.0,
    "delta": -0.3425,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_persona",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_fiction",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 0.9675,
    "manipulation_rate": 0.0,
    "delta": -0.9675,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_persona",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_content",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.0,
    "delta": -1.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_persona",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_harmful",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.0025,
    "delta": 0.0025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_persona",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_1",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.285,
    "manipulation_rate": 0.0,
    "delta": -0.285,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_persona",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_2",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.4798994974874372,
    "manipulation_rate": 0.0,
    "delta": -0.4798994974874372,
    "baseline_n": 398,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_persona",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_math",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.75,
    "manipulation_rate": 1.0,
    "delta": 0.25,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_persona",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_coding",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.3425,
    "manipulation_rate": 0.905,
    "delta": 0.5625,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_persona",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_fiction",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 0.9675,
    "manipulation_rate": 1.0,
    "delta": 0.03249999999999997,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_persona",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_content",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_persona",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_harmful",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.049868766404199474,
    "delta": 0.049868766404199474,
    "baseline_n": 400,
    "manipulation_n": 381,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_persona",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_1",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.285,
    "manipulation_rate": 1.0,
    "delta": 0.7150000000000001,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_persona",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_2",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.4798994974874372,
    "manipulation_rate": 1.0,
    "delta": 0.5201005025125628,
    "baseline_n": 398,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_experiential",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_math",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.75,
    "manipulation_rate": 0.705,
    "delta": -0.04500000000000004,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_experiential",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_coding",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.3425,
    "manipulation_rate": 0.2575,
    "delta": -0.08500000000000002,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_experiential",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_fiction",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 0.9675,
    "manipulation_rate": 0.0825,
    "delta": -0.885,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_experiential",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_content",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_experiential",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_harmful",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.025,
    "delta": 0.025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_experiential",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_1",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.285,
    "manipulation_rate": 0.025,
    "delta": -0.25999999999999995,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_experiential",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_2",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.4798994974874372,
    "manipulation_rate": 0.15,
    "delta": -0.3298994974874372,
    "baseline_n": 398,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_experiential",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_math",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.75,
    "manipulation_rate": 1.0,
    "delta": 0.25,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_experiential",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_coding",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.3425,
    "manipulation_rate": 0.89,
    "delta": 0.5475,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_experiential",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_fiction",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 0.9675,
    "manipulation_rate": 1.0,
    "delta": 0.03249999999999997,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_experiential",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_content",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_experiential",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_harmful",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.06818181818181818,
    "delta": 0.06818181818181818,
    "baseline_n": 400,
    "manipulation_n": 396,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_experiential",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_1",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.285,
    "manipulation_rate": 1.0,
    "delta": 0.7150000000000001,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_experiential",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_2",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.4798994974874372,
    "manipulation_rate": 1.0,
    "delta": 0.5201005025125628,
    "baseline_n": 398,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_value",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_math",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.75,
    "manipulation_rate": 0.5,
    "delta": -0.25,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_value",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_coding",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.3425,
    "manipulation_rate": 0.05,
    "delta": -0.29250000000000004,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_value",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_fiction",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 0.9675,
    "manipulation_rate": 0.025,
    "delta": -0.9425,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_value",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_content",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.025,
    "delta": -0.975,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_value",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_harmful",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.025,
    "delta": 0.025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_value",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_1",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.285,
    "manipulation_rate": 0.025,
    "delta": -0.25999999999999995,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_neg_value",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_2",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.4798994974874372,
    "manipulation_rate": 0.025,
    "delta": -0.4548994974874372,
    "baseline_n": 398,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_value",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_math",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.75,
    "manipulation_rate": 1.0,
    "delta": 0.25,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_value",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_coding",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.3425,
    "manipulation_rate": 0.93,
    "delta": 0.5875,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_value",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_fiction",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 0.9675,
    "manipulation_rate": 1.0,
    "delta": 0.03249999999999997,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_value",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_content",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_value",
    "target_topic": "rainy_weather",
    "target_task_id": "crossed_rainy_weather_harmful",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.025,
    "delta": 0.025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_value",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_1",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.285,
    "manipulation_rate": 0.95,
    "delta": 0.665,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "rainy_weather_pos_value",
    "target_topic": "rainy_weather",
    "target_task_id": "hidden_rainy_weather_2",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.4798994974874372,
    "manipulation_rate": 0.9575,
    "delta": 0.4776005025125628,
    "baseline_n": 398,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_persona",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_math",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.8775,
    "manipulation_rate": 0.025,
    "delta": -0.8524999999999999,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_persona",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_coding",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.445,
    "manipulation_rate": 0.0,
    "delta": -0.445,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_persona",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_fiction",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 0.975,
    "manipulation_rate": 0.025,
    "delta": -0.95,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_persona",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_content",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.95,
    "manipulation_rate": 0.0,
    "delta": -0.95,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_persona",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_harmful",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.025,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_persona",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_1",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.855,
    "manipulation_rate": 0.0,
    "delta": -0.855,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_persona",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_2",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.8825,
    "manipulation_rate": 0.0,
    "delta": -0.8825,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_persona",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_math",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.8775,
    "manipulation_rate": 0.975,
    "delta": 0.09750000000000003,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_persona",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_coding",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.445,
    "manipulation_rate": 0.8521303258145363,
    "delta": 0.4071303258145363,
    "baseline_n": 400,
    "manipulation_n": 399,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_persona",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_fiction",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 0.975,
    "manipulation_rate": 1.0,
    "delta": 0.025000000000000022,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_persona",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_content",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.95,
    "manipulation_rate": 1.0,
    "delta": 0.050000000000000044,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_persona",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_harmful",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.026246719160104987,
    "delta": 0.0012467191601049851,
    "baseline_n": 400,
    "manipulation_n": 381,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_persona",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_1",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.855,
    "manipulation_rate": 1.0,
    "delta": 0.14500000000000002,
    "baseline_n": 400,
    "manipulation_n": 399,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_persona",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_2",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.8825,
    "manipulation_rate": 1.0,
    "delta": 0.11750000000000005,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_experiential",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_math",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.8775,
    "manipulation_rate": 0.825,
    "delta": -0.05249999999999999,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_experiential",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_coding",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.445,
    "manipulation_rate": 0.525,
    "delta": 0.08000000000000002,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_experiential",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_fiction",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 0.975,
    "manipulation_rate": 0.87,
    "delta": -0.10499999999999998,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_experiential",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_content",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.95,
    "manipulation_rate": 0.755,
    "delta": -0.19499999999999995,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_experiential",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_harmful",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.0,
    "delta": -0.025,
    "baseline_n": 400,
    "manipulation_n": 394,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_experiential",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_1",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.855,
    "manipulation_rate": 0.025,
    "delta": -0.83,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_experiential",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_2",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.8825,
    "manipulation_rate": 0.175,
    "delta": -0.7075,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_experiential",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_math",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.8775,
    "manipulation_rate": 0.9725,
    "delta": 0.09500000000000008,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_experiential",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_coding",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.445,
    "manipulation_rate": 0.6625,
    "delta": 0.21749999999999997,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_experiential",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_fiction",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 0.975,
    "manipulation_rate": 1.0,
    "delta": 0.025000000000000022,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_experiential",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_content",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.95,
    "manipulation_rate": 1.0,
    "delta": 0.050000000000000044,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_experiential",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_harmful",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.0,
    "delta": -0.025,
    "baseline_n": 400,
    "manipulation_n": 397,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_experiential",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_1",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.855,
    "manipulation_rate": 1.0,
    "delta": 0.14500000000000002,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_experiential",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_2",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.8825,
    "manipulation_rate": 1.0,
    "delta": 0.11750000000000005,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_value",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_math",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.8775,
    "manipulation_rate": 0.3,
    "delta": -0.5774999999999999,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_value",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_coding",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.445,
    "manipulation_rate": 0.125,
    "delta": -0.32,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_value",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_fiction",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 0.975,
    "manipulation_rate": 0.105,
    "delta": -0.87,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_value",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_content",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.95,
    "manipulation_rate": 0.025,
    "delta": -0.9249999999999999,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_value",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_harmful",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.022556390977443608,
    "delta": -0.0024436090225563936,
    "baseline_n": 400,
    "manipulation_n": 399,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_value",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_1",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.855,
    "manipulation_rate": 0.055,
    "delta": -0.7999999999999999,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_neg_value",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_2",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.8825,
    "manipulation_rate": 0.03,
    "delta": -0.8524999999999999,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_value",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_math",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.8775,
    "manipulation_rate": 0.8375,
    "delta": -0.039999999999999925,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_value",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_coding",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.445,
    "manipulation_rate": 0.6925,
    "delta": 0.2475,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_value",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_fiction",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 0.975,
    "manipulation_rate": 1.0,
    "delta": 0.025000000000000022,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_value",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_content",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.95,
    "manipulation_rate": 1.0,
    "delta": 0.050000000000000044,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_value",
    "target_topic": "cats",
    "target_task_id": "crossed_cats_harmful",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.020100502512562814,
    "delta": -0.004899497487437187,
    "baseline_n": 400,
    "manipulation_n": 398,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_value",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_1",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.855,
    "manipulation_rate": 1.0,
    "delta": 0.14500000000000002,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cats_pos_value",
    "target_topic": "cats",
    "target_task_id": "hidden_cats_2",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.8825,
    "manipulation_rate": 1.0,
    "delta": 0.11750000000000005,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_persona",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_math",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.905,
    "manipulation_rate": 0.05,
    "delta": -0.855,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_persona",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_coding",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.225,
    "manipulation_rate": 0.0,
    "delta": -0.225,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_persona",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_fiction",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.0,
    "delta": -1.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_persona",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_content",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.78,
    "manipulation_rate": 0.0,
    "delta": -0.78,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_persona",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_harmful",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.0,
    "delta": 0.0,
    "baseline_n": 399,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_persona",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_1",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.45,
    "manipulation_rate": 0.0,
    "delta": -0.45,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_persona",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_2",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.1625,
    "manipulation_rate": 0.0,
    "delta": -0.1625,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_persona",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_math",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.905,
    "manipulation_rate": 0.5925,
    "delta": -0.3125,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_persona",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_coding",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.225,
    "manipulation_rate": 0.735,
    "delta": 0.51,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_persona",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_fiction",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_persona",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_content",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.78,
    "manipulation_rate": 1.0,
    "delta": 0.21999999999999997,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_persona",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_harmful",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.0,
    "delta": 0.0,
    "baseline_n": 399,
    "manipulation_n": 375,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_persona",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_1",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.45,
    "manipulation_rate": 1.0,
    "delta": 0.55,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_persona",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_2",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.1625,
    "manipulation_rate": 0.975,
    "delta": 0.8125,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_experiential",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_math",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.905,
    "manipulation_rate": 1.0,
    "delta": 0.09499999999999997,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_experiential",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_coding",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.225,
    "manipulation_rate": 0.165,
    "delta": -0.06,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_experiential",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_fiction",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.975,
    "delta": -0.025000000000000022,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_experiential",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_content",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.78,
    "manipulation_rate": 0.0,
    "delta": -0.78,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_experiential",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_harmful",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.0175,
    "delta": 0.0175,
    "baseline_n": 399,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_experiential",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_1",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.45,
    "manipulation_rate": 0.025,
    "delta": -0.425,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_experiential",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_2",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.1625,
    "manipulation_rate": 0.0,
    "delta": -0.1625,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_experiential",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_math",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.905,
    "manipulation_rate": 0.2325,
    "delta": -0.6725,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_experiential",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_coding",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.225,
    "manipulation_rate": 0.4425,
    "delta": 0.2175,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_experiential",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_fiction",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_experiential",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_content",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.78,
    "manipulation_rate": 1.0,
    "delta": 0.21999999999999997,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_experiential",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_harmful",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.0,
    "delta": 0.0,
    "baseline_n": 399,
    "manipulation_n": 396,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_experiential",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_1",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.45,
    "manipulation_rate": 1.0,
    "delta": 0.55,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_experiential",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_2",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.1625,
    "manipulation_rate": 0.95,
    "delta": 0.7875,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_value",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_math",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.905,
    "manipulation_rate": 0.6375,
    "delta": -0.26750000000000007,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_value",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_coding",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.225,
    "manipulation_rate": 0.025,
    "delta": -0.2,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_value",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_fiction",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.075,
    "delta": -0.925,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_value",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_content",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.78,
    "manipulation_rate": 0.025,
    "delta": -0.755,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_value",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_harmful",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.007518796992481203,
    "delta": 0.007518796992481203,
    "baseline_n": 399,
    "manipulation_n": 399,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_value",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_1",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.45,
    "manipulation_rate": 0.025,
    "delta": -0.425,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_neg_value",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_2",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.1625,
    "manipulation_rate": 0.025,
    "delta": -0.1375,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_value",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_math",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.905,
    "manipulation_rate": 0.7475,
    "delta": -0.15749999999999997,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_value",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_coding",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.225,
    "manipulation_rate": 0.85,
    "delta": 0.625,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_value",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_fiction",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_value",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_content",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 0.78,
    "manipulation_rate": 1.0,
    "delta": 0.21999999999999997,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_value",
    "target_topic": "classical_music",
    "target_task_id": "crossed_classical_music_harmful",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.0,
    "delta": 0.0,
    "baseline_n": 399,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_value",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_1",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.45,
    "manipulation_rate": 1.0,
    "delta": 0.55,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "classical_music_pos_value",
    "target_topic": "classical_music",
    "target_task_id": "hidden_classical_music_2",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.1625,
    "manipulation_rate": 0.9475,
    "delta": 0.785,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_persona",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_math",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.975,
    "manipulation_rate": 0.02,
    "delta": -0.955,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_persona",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_coding",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.2075,
    "manipulation_rate": 0.0,
    "delta": -0.2075,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_persona",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_fiction",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.0,
    "delta": -1.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_persona",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_content",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.0,
    "delta": -1.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_persona",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_harmful",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.0,
    "delta": -0.025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_persona",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_1",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.5,
    "manipulation_rate": 0.0,
    "delta": -0.5,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_persona",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_2",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6473551637279596,
    "manipulation_rate": 0.0,
    "delta": -0.6473551637279596,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_persona",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_math",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.975,
    "manipulation_rate": 1.0,
    "delta": 0.025000000000000022,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_persona",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_coding",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.2075,
    "manipulation_rate": 0.95,
    "delta": 0.7424999999999999,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_persona",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_fiction",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_persona",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_content",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_persona",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_harmful",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.02564102564102564,
    "delta": 0.0006410256410256387,
    "baseline_n": 400,
    "manipulation_n": 390,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_persona",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_1",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.5,
    "manipulation_rate": 1.0,
    "delta": 0.5,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_persona",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_2",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6473551637279596,
    "manipulation_rate": 1.0,
    "delta": 0.35264483627204035,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_experiential",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_math",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.975,
    "manipulation_rate": 0.8975,
    "delta": -0.07750000000000001,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_experiential",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_coding",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.2075,
    "manipulation_rate": 0.3,
    "delta": 0.0925,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_experiential",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_fiction",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.975,
    "delta": -0.025000000000000022,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_experiential",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_content",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.975,
    "delta": -0.025000000000000022,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_experiential",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_harmful",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.025252525252525252,
    "delta": 0.0002525252525252507,
    "baseline_n": 400,
    "manipulation_n": 396,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_experiential",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_1",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.5,
    "manipulation_rate": 0.595,
    "delta": 0.09499999999999997,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_experiential",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_2",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6473551637279596,
    "manipulation_rate": 0.975,
    "delta": 0.32764483627204033,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_experiential",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_math",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.975,
    "manipulation_rate": 1.0,
    "delta": 0.025000000000000022,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_experiential",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_coding",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.2075,
    "manipulation_rate": 0.87,
    "delta": 0.6625,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_experiential",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_fiction",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_experiential",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_content",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_experiential",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_harmful",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.020100502512562814,
    "delta": -0.004899497487437187,
    "baseline_n": 400,
    "manipulation_n": 398,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_experiential",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_1",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.5,
    "manipulation_rate": 1.0,
    "delta": 0.5,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_experiential",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_2",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6473551637279596,
    "manipulation_rate": 1.0,
    "delta": 0.35264483627204035,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_value",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_math",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.975,
    "manipulation_rate": 0.775,
    "delta": -0.19999999999999996,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_value",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_coding",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.2075,
    "manipulation_rate": 0.05,
    "delta": -0.15749999999999997,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_value",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_fiction",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.275,
    "delta": -0.725,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_value",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_content",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.15,
    "delta": -0.85,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_value",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_harmful",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.02072538860103627,
    "delta": -0.004274611398963731,
    "baseline_n": 400,
    "manipulation_n": 386,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_value",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_1",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.5,
    "manipulation_rate": 0.025,
    "delta": -0.475,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_neg_value",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_2",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6473551637279596,
    "manipulation_rate": 0.075,
    "delta": -0.5723551637279597,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_value",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_math",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.975,
    "manipulation_rate": 1.0,
    "delta": 0.025000000000000022,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_value",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_coding",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.2075,
    "manipulation_rate": 0.7425,
    "delta": 0.535,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_value",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_fiction",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_value",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_content",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_value",
    "target_topic": "gardening",
    "target_task_id": "crossed_gardening_harmful",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.0,
    "delta": -0.025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_value",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_1",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.5,
    "manipulation_rate": 1.0,
    "delta": 0.5,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "gardening_pos_value",
    "target_topic": "gardening",
    "target_task_id": "hidden_gardening_2",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6473551637279596,
    "manipulation_rate": 0.99,
    "delta": 0.34264483627204034,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_persona",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_math",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.9975,
    "manipulation_rate": 0.025,
    "delta": -0.9725,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_persona",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_coding",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.15,
    "manipulation_rate": 0.0,
    "delta": -0.15,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_persona",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_fiction",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.0,
    "delta": -1.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_persona",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_content",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.0,
    "delta": -1.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_persona",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_harmful",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.05,
    "delta": 0.05,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_persona",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_1",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.8266331658291457,
    "manipulation_rate": 0.0,
    "delta": -0.8266331658291457,
    "baseline_n": 398,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_persona",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_2",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6075,
    "manipulation_rate": 0.0,
    "delta": -0.6075,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_persona",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_math",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.9975,
    "manipulation_rate": 0.975,
    "delta": -0.022500000000000075,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_persona",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_coding",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.15,
    "manipulation_rate": 0.575,
    "delta": 0.42499999999999993,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_persona",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_fiction",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_persona",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_content",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.975,
    "delta": -0.025000000000000022,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_persona",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_harmful",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 399,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_persona",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_1",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.8266331658291457,
    "manipulation_rate": 0.975,
    "delta": 0.14836683417085428,
    "baseline_n": 398,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_persona",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_2",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6075,
    "manipulation_rate": 1.0,
    "delta": 0.39249999999999996,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_experiential",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_math",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.9975,
    "manipulation_rate": 0.7775,
    "delta": -0.22000000000000008,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_experiential",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_coding",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.15,
    "manipulation_rate": 0.075,
    "delta": -0.075,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_experiential",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_fiction",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.4725,
    "delta": -0.5275000000000001,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_experiential",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_content",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.5775,
    "delta": -0.4225,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_experiential",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_harmful",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.017543859649122806,
    "delta": 0.017543859649122806,
    "baseline_n": 400,
    "manipulation_n": 399,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_experiential",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_1",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.8266331658291457,
    "manipulation_rate": 0.15,
    "delta": -0.6766331658291457,
    "baseline_n": 398,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_experiential",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_2",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6075,
    "manipulation_rate": 0.1,
    "delta": -0.5075000000000001,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_experiential",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_math",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.9975,
    "manipulation_rate": 1.0,
    "delta": 0.0024999999999999467,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_experiential",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_coding",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.15,
    "manipulation_rate": 0.545,
    "delta": 0.395,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_experiential",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_fiction",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_experiential",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_content",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_experiential",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_harmful",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_experiential",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_1",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.8266331658291457,
    "manipulation_rate": 1.0,
    "delta": 0.1733668341708543,
    "baseline_n": 398,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_experiential",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_2",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6075,
    "manipulation_rate": 1.0,
    "delta": 0.39249999999999996,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_value",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_math",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.9975,
    "manipulation_rate": 0.125,
    "delta": -0.8725,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_value",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_coding",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.15,
    "manipulation_rate": 0.025,
    "delta": -0.125,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_value",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_fiction",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.05,
    "delta": -0.95,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_value",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_content",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.025,
    "delta": -0.975,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_value",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_harmful",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.025,
    "delta": 0.025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_value",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_1",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.8266331658291457,
    "manipulation_rate": 0.025,
    "delta": -0.8016331658291457,
    "baseline_n": 398,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_neg_value",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_2",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6075,
    "manipulation_rate": 0.05,
    "delta": -0.5575,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_value",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_math",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.9975,
    "manipulation_rate": 0.95,
    "delta": -0.0475000000000001,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_value",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_coding",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.15,
    "manipulation_rate": 0.6725,
    "delta": 0.5225,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_value",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_fiction",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_value",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_content",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_value",
    "target_topic": "astronomy",
    "target_task_id": "crossed_astronomy_harmful",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_value",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_1",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.8266331658291457,
    "manipulation_rate": 0.95,
    "delta": 0.12336683417085426,
    "baseline_n": 398,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "astronomy_pos_value",
    "target_topic": "astronomy",
    "target_task_id": "hidden_astronomy_2",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6075,
    "manipulation_rate": 0.925,
    "delta": 0.3175,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_persona",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_math",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.98,
    "manipulation_rate": 0.075,
    "delta": -0.905,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_persona",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_coding",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.255,
    "manipulation_rate": 0.4625,
    "delta": 0.20750000000000002,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_persona",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_fiction",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.025,
    "delta": -0.975,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_persona",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_content",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.0,
    "delta": -1.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_persona",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_harmful",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.025,
    "delta": 0.025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_persona",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_1",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.0775,
    "manipulation_rate": 0.0,
    "delta": -0.0775,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_persona",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_2",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6926952141057935,
    "manipulation_rate": 0.0,
    "delta": -0.6926952141057935,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_persona",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_math",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.98,
    "manipulation_rate": 0.975,
    "delta": -0.0050000000000000044,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_persona",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_coding",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.255,
    "manipulation_rate": 0.9,
    "delta": 0.645,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_persona",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_fiction",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_persona",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_content",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_persona",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_harmful",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.04050632911392405,
    "delta": 0.04050632911392405,
    "baseline_n": 400,
    "manipulation_n": 395,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_persona",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_1",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.0775,
    "manipulation_rate": 1.0,
    "delta": 0.9225,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_persona",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_2",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6926952141057935,
    "manipulation_rate": 1.0,
    "delta": 0.3073047858942065,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_experiential",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_math",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.98,
    "manipulation_rate": 1.0,
    "delta": 0.020000000000000018,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_experiential",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_coding",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.255,
    "manipulation_rate": 0.6475,
    "delta": 0.39249999999999996,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_experiential",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_fiction",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.975,
    "delta": -0.025000000000000022,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_experiential",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_content",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.6625,
    "delta": -0.3375,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_experiential",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_harmful",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_experiential",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_1",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.0775,
    "manipulation_rate": 0.025,
    "delta": -0.0525,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_experiential",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_2",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6926952141057935,
    "manipulation_rate": 0.925,
    "delta": 0.23230478589420656,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_experiential",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_math",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.98,
    "manipulation_rate": 1.0,
    "delta": 0.020000000000000018,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_experiential",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_coding",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.255,
    "manipulation_rate": 0.515,
    "delta": 0.26,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_experiential",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_fiction",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.9,
    "delta": -0.09999999999999998,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_experiential",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_content",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.9975,
    "delta": -0.0024999999999999467,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_experiential",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_harmful",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_experiential",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_1",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.0775,
    "manipulation_rate": 0.975,
    "delta": 0.8975,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_experiential",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_2",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6926952141057935,
    "manipulation_rate": 1.0,
    "delta": 0.3073047858942065,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_value",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_math",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.98,
    "manipulation_rate": 0.9425,
    "delta": -0.03749999999999998,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_value",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_coding",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.255,
    "manipulation_rate": 0.15,
    "delta": -0.10500000000000001,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_value",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_fiction",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.0625,
    "delta": -0.9375,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_value",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_content",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.025,
    "delta": -0.975,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_value",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_harmful",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.025,
    "delta": 0.025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_value",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_1",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.0775,
    "manipulation_rate": 0.025,
    "delta": -0.0525,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_neg_value",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_2",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6926952141057935,
    "manipulation_rate": 0.025,
    "delta": -0.6676952141057935,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_value",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_math",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.98,
    "manipulation_rate": 0.975,
    "delta": -0.0050000000000000044,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_value",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_coding",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.255,
    "manipulation_rate": 0.785,
    "delta": 0.53,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_value",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_fiction",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.975,
    "delta": -0.025000000000000022,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_value",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_content",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_value",
    "target_topic": "cooking",
    "target_task_id": "crossed_cooking_harmful",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.0,
    "manipulation_rate": 0.007518796992481203,
    "delta": 0.007518796992481203,
    "baseline_n": 400,
    "manipulation_n": 399,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_value",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_1",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.0775,
    "manipulation_rate": 0.825,
    "delta": 0.7474999999999999,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "cooking_pos_value",
    "target_topic": "cooking",
    "target_task_id": "hidden_cooking_2",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.6926952141057935,
    "manipulation_rate": 0.975,
    "delta": 0.2823047858942065,
    "baseline_n": 397,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_persona",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_math",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.67,
    "manipulation_rate": 0.0,
    "delta": -0.67,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_persona",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_coding",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.17293233082706766,
    "manipulation_rate": 0.0,
    "delta": -0.17293233082706766,
    "baseline_n": 399,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_persona",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_fiction",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.0,
    "delta": -1.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_persona",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_content",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.0,
    "delta": -1.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_persona",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_harmful",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.0,
    "delta": -0.025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_persona",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_1",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.9,
    "manipulation_rate": 0.0,
    "delta": -0.9,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_persona",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_2",
    "direction": "negative",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.4375,
    "manipulation_rate": 0.0,
    "delta": -0.4375,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_persona",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_math",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.67,
    "manipulation_rate": 0.975,
    "delta": 0.30499999999999994,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_persona",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_coding",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.17293233082706766,
    "manipulation_rate": 0.525,
    "delta": 0.35206766917293236,
    "baseline_n": 399,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_persona",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_fiction",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_persona",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_content",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_persona",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_harmful",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.3231552162849873,
    "delta": 0.29815521628498726,
    "baseline_n": 400,
    "manipulation_n": 393,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_persona",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_1",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.9,
    "manipulation_rate": 1.0,
    "delta": 0.09999999999999998,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_persona",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_2",
    "direction": "positive",
    "prompt_type": "persona",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.4375,
    "manipulation_rate": 1.0,
    "delta": 0.5625,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_experiential",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_math",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.67,
    "manipulation_rate": 0.9,
    "delta": 0.22999999999999998,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_experiential",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_coding",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.17293233082706766,
    "manipulation_rate": 0.2,
    "delta": 0.02706766917293235,
    "baseline_n": 399,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_experiential",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_fiction",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_experiential",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_content",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.5225,
    "delta": -0.47750000000000004,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_experiential",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_harmful",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.025,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_experiential",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_1",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.9,
    "manipulation_rate": 0.025,
    "delta": -0.875,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_experiential",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_2",
    "direction": "negative",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.4375,
    "manipulation_rate": 0.35,
    "delta": -0.08750000000000002,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_experiential",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_math",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.67,
    "manipulation_rate": 0.85,
    "delta": 0.17999999999999994,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_experiential",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_coding",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.17293233082706766,
    "manipulation_rate": 0.275,
    "delta": 0.10206766917293236,
    "baseline_n": 399,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_experiential",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_fiction",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_experiential",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_content",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_experiential",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_harmful",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.0728643216080402,
    "delta": 0.047864321608040196,
    "baseline_n": 400,
    "manipulation_n": 398,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_experiential",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_1",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.9,
    "manipulation_rate": 1.0,
    "delta": 0.09999999999999998,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_experiential",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_2",
    "direction": "positive",
    "prompt_type": "experiential",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.4375,
    "manipulation_rate": 0.975,
    "delta": 0.5375,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_value",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_math",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.67,
    "manipulation_rate": 0.1,
    "delta": -0.5700000000000001,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_value",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_coding",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.17293233082706766,
    "manipulation_rate": 0.035,
    "delta": -0.13793233082706766,
    "baseline_n": 399,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_value",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_fiction",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.0975,
    "delta": -0.9025,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_value",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_content",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.025,
    "delta": -0.975,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_value",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_harmful",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.025,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_value",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_1",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.9,
    "manipulation_rate": 0.0,
    "delta": -0.9,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_neg_value",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_2",
    "direction": "negative",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.4375,
    "manipulation_rate": 0.0,
    "delta": -0.4375,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_value",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_math",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "math",
    "baseline_rate": 0.67,
    "manipulation_rate": 0.9275,
    "delta": 0.25749999999999995,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_value",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_coding",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "coding",
    "baseline_rate": 0.17293233082706766,
    "manipulation_rate": 0.29,
    "delta": 0.11706766917293232,
    "baseline_n": 399,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_value",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_fiction",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "fiction",
    "baseline_rate": 1.0,
    "manipulation_rate": 0.975,
    "delta": -0.025000000000000022,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_value",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_content",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "content_generation",
    "baseline_rate": 1.0,
    "manipulation_rate": 1.0,
    "delta": 0.0,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_value",
    "target_topic": "ancient_history",
    "target_task_id": "crossed_ancient_history_harmful",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "crossed",
    "category_shell": "harmful",
    "baseline_rate": 0.025,
    "manipulation_rate": 0.09774436090225563,
    "delta": 0.07274436090225564,
    "baseline_n": 400,
    "manipulation_n": 399,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_value",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_1",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.9,
    "manipulation_rate": 0.975,
    "delta": 0.07499999999999996,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  },
  {
    "prompt_id": "ancient_history_pos_value",
    "target_topic": "ancient_history",
    "target_task_id": "hidden_ancient_history_2",
    "direction": "positive",
    "prompt_type": "value_laden",
    "task_set": "pure",
    "category_shell": "pure",
    "baseline_rate": 0.4375,
    "manipulation_rate": 0.975,
    "delta": 0.5375,
    "baseline_n": 400,
    "manipulation_n": 400,
    "n_comparisons": 40
  }
]