fitting_method: active_learning
converged: true
neg_log_likelihood: 21623.298994270008
n_iterations: 77
n_function_evals: 83
termination_message: 'CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL'
gradient_norm: 29.90828718202448
history:
  loss:
  - 27570.777224182562
  - 24472.29788068515
  - 24006.96128623873
  - 23036.902691829506
  - 22651.86655955771
  - 22433.91299353414
  - 22297.556918687704
  - 22205.04588018394
  - 22081.87870546092
  - 22023.95057971902
  - 21971.531138541322
  - 21918.085090354547
  - 21896.461757321318
  - 21864.513230586675
  - 21850.167234197594
  - 21832.705822073876
  - 21813.03968879998
  - 21794.648808578062
  - 21784.41127883875
  - 21769.77209951735
  - 21761.50620848962
  - 21749.94938665521
  - 21742.769293697573
  - 21736.10089246445
  - 21726.46091551346
  - 21721.140819109267
  - 21713.096415147756
  - 21709.38927696007
  - 21705.44886625881
  - 21697.94349280572
  - 21694.530452235223
  - 21687.936690669154
  - 21683.01771571628
  - 21678.9283139367
  - 21674.377450754615
  - 21668.698572204445
  - 21664.5907716097
  - 21661.17377554955
  - 21657.605777465935
  - 21654.910920882587
  - 21652.324554120532
  - 21649.991620060915
  - 21647.52412867141
  - 21645.81107680242
  - 21644.184268198784
  - 21642.791099951697
  - 21641.895981217684
  - 21640.720130106034
  - 21640.039922515498
  - 21638.78248511382
  - 21638.081504228332
  - 21637.43207432042
  - 21635.964063089963
  - 21635.200310392207
  - 21633.968786692916
  - 21633.367793515456
  - 21632.412566213556
  - 21631.767796409313
  - 21631.064055090465
  - 21630.577879045093
  - 21630.23458594992
  - 21629.84718937611
  - 21629.367227515897
  - 21628.950554988616
  - 21628.46074059371
  - 21628.147578333992
  - 21627.367110868574
  - 21626.85909211309
  - 21626.272816553865
  - 21625.848339152813
  - 21625.232651581682
  - 21624.901091062507
  - 21624.595557815686
  - 21624.091094703563
  - 21623.87679804455
  - 21623.52773006333
  - 21623.298994270008
  sigma_max:
  - 1.0
  - 2.0507852120881376
  - 2.3870056093871246
  - 5.652336684078156
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
config:
  n_tasks: 500
  seed: 42
  generation_seed: 0
