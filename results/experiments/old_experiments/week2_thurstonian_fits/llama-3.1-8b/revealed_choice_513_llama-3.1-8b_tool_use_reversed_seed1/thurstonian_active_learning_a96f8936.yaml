fitting_method: active_learning
converged: true
neg_log_likelihood: 16331.157739825318
n_iterations: 81
n_function_evals: 85
termination_message: 'CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL'
gradient_norm: 21.467226839954975
history:
  loss:
  - 21520.329624113197
  - 19079.39460941848
  - 18559.760201031742
  - 17542.457196197982
  - 17237.21389240962
  - 17011.15361944466
  - 16875.45615554268
  - 16750.810638542844
  - 16729.87457561992
  - 16660.766487420602
  - 16632.335812425703
  - 16596.294200253127
  - 16567.09782912512
  - 16539.59121087338
  - 16519.357917852096
  - 16497.38816189859
  - 16482.78283096754
  - 16472.311771319946
  - 16462.46524690138
  - 16453.85539368529
  - 16444.29673686778
  - 16432.989291657654
  - 16428.57593329635
  - 16421.2509518238
  - 16415.19455793307
  - 16408.68202701995
  - 16402.984369658923
  - 16398.503535202683
  - 16392.32296523305
  - 16387.194533449823
  - 16383.301775685819
  - 16380.290505288138
  - 16377.008780090577
  - 16373.716511165856
  - 16371.264197276894
  - 16368.024850598487
  - 16364.802814712437
  - 16361.97154194693
  - 16359.620381967465
  - 16358.127723985313
  - 16356.339547167096
  - 16354.93136665308
  - 16353.431832451157
  - 16352.323209378492
  - 16351.317090397424
  - 16350.57039606997
  - 16349.673857875758
  - 16348.548442717225
  - 16347.843352223057
  - 16347.013992075847
  - 16345.944650141735
  - 16345.218089795759
  - 16343.71099056158
  - 16342.747214454424
  - 16341.644116872703
  - 16340.845175368091
  - 16339.386112660119
  - 16338.857121103396
  - 16338.319299932875
  - 16337.683103970718
  - 16337.230433316348
  - 16336.41777992649
  - 16336.12607360158
  - 16335.74173544789
  - 16335.471620146644
  - 16335.146999381644
  - 16334.812579587688
  - 16334.489269144815
  - 16334.130227023026
  - 16333.871782766179
  - 16333.558301629853
  - 16333.299933803046
  - 16333.016583001274
  - 16332.819324124199
  - 16332.516610479764
  - 16332.249523100492
  - 16331.891435097048
  - 16331.655168866197
  - 16331.476648112515
  - 16331.324849956347
  - 16331.157739825318
  sigma_max:
  - 1.0
  - 2.572941710210234
  - 3.034083016253608
  - 7.328298864030352
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
config:
  n_tasks: 500
  seed: 42
  generation_seed: 1
