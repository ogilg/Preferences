fitting_method: active_learning
converged: true
neg_log_likelihood: 16718.879990962323
n_iterations: 80
n_function_evals: 83
termination_message: 'CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL'
gradient_norm: 11.326506484436022
history:
  loss:
  - 21888.6299034401
  - 19459.078148680594
  - 18859.564386420276
  - 17768.255035067792
  - 17590.991211761913
  - 17307.159396821986
  - 17223.371824309375
  - 17092.14640611535
  - 17075.45812453598
  - 17009.296580351594
  - 16989.383460532248
  - 16955.560862795253
  - 16922.482655948697
  - 16907.57471888915
  - 16881.12787187121
  - 16869.639207926786
  - 16854.644228820252
  - 16840.429526355514
  - 16829.193596601202
  - 16816.906217611544
  - 16808.628122616232
  - 16800.19970455106
  - 16789.748149315295
  - 16785.51300859041
  - 16780.661968478726
  - 16775.1012263414
  - 16771.917959903392
  - 16766.15830758796
  - 16763.499965882278
  - 16761.225098609113
  - 16759.360300563654
  - 16757.612456413994
  - 16755.077265964595
  - 16753.747268264713
  - 16752.15692378166
  - 16751.13624000089
  - 16750.215849311884
  - 16748.979444727447
  - 16747.651772193985
  - 16746.940022620212
  - 16745.77890415302
  - 16745.142221115086
  - 16744.361174754937
  - 16742.989550840874
  - 16742.30348077296
  - 16741.924434656885
  - 16739.71335908707
  - 16739.278405049547
  - 16737.776806569404
  - 16736.62105369578
  - 16735.441764054423
  - 16734.723812732744
  - 16733.985474446683
  - 16733.00595029683
  - 16731.927155563637
  - 16730.697568962885
  - 16729.795134524968
  - 16728.932300185686
  - 16728.275353655757
  - 16727.877387193817
  - 16727.410749371473
  - 16727.25255999283
  - 16727.08450085533
  - 16726.603131258547
  - 16726.46073873811
  - 16726.21454114843
  - 16725.95179760684
  - 16725.679761744206
  - 16725.14002662601
  - 16724.61022256367
  - 16723.66032275009
  - 16723.076763041834
  - 16722.469795508845
  - 16722.023179382824
  - 16721.45297772045
  - 16720.619468098197
  - 16720.148620499953
  - 16719.819629757003
  - 16719.088789643218
  - 16718.879990962323
  sigma_max:
  - 1.0
  - 1.9366671169742393
  - 2.2952534158920224
  - 5.810771387342373
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
config:
  n_tasks: 500
  seed: 42
  generation_seed: 1
