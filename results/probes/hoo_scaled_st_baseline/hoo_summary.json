{
  "experiment_name": "hoo_scaled_st_baseline",
  "created_at": "2026-02-11T23:47:14.147454",
  "grouping": "topic",
  "hold_out_size": 3,
  "all_groups": [
    "coding",
    "content_generation",
    "fiction",
    "harmful_request",
    "knowledge_qa",
    "math",
    "persuasive_writing",
    "summarization"
  ],
  "group_sizes": {
    "coding": 125,
    "content_generation": 375,
    "fiction": 161,
    "harmful_request": 714,
    "knowledge_qa": 644,
    "math": 672,
    "persuasive_writing": 93,
    "summarization": 26
  },
  "n_folds": 56,
  "layers": [
    0
  ],
  "folds": [
    {
      "fold_idx": 0,
      "held_out_groups": [
        "coding",
        "content_generation",
        "fiction"
      ],
      "train_groups": [
        "harmful_request",
        "knowledge_qa",
        "math",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.607444740419719,
          "val_r": 0.7799226947860439,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.6544084163885013,
          "hoo_r": 0.1292775656978945,
          "hoo_n_samples": 661,
          "n_train": 2339,
          "n_eval": 661,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold0_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 1,
      "held_out_groups": [
        "coding",
        "content_generation",
        "harmful_request"
      ],
      "train_groups": [
        "fiction",
        "knowledge_qa",
        "math",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.2608311742327116,
          "val_r": 0.5174866733066793,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.9428261693359947,
          "hoo_r": 0.385984815662436,
          "hoo_n_samples": 1214,
          "n_train": 1786,
          "n_eval": 1214,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold1_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 2,
      "held_out_groups": [
        "coding",
        "content_generation",
        "knowledge_qa"
      ],
      "train_groups": [
        "fiction",
        "harmful_request",
        "math",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.6882022888516585,
          "val_r": 0.830465557629046,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.503164972613616,
          "hoo_r": 0.11223754284834146,
          "hoo_n_samples": 1144,
          "n_train": 1856,
          "n_eval": 1144,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold2_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 3,
      "held_out_groups": [
        "coding",
        "content_generation",
        "math"
      ],
      "train_groups": [
        "fiction",
        "harmful_request",
        "knowledge_qa",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5153930802550948,
          "val_r": 0.7195943001393003,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -2.685739626073156,
          "hoo_r": 0.1640917222347307,
          "hoo_n_samples": 1172,
          "n_train": 1828,
          "n_eval": 1172,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold3_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 4,
      "held_out_groups": [
        "coding",
        "content_generation",
        "persuasive_writing"
      ],
      "train_groups": [
        "fiction",
        "harmful_request",
        "knowledge_qa",
        "math",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5997456653370816,
          "val_r": 0.77526973056566,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.5135411202319287,
          "hoo_r": 0.11850598942170204,
          "hoo_n_samples": 593,
          "n_train": 2407,
          "n_eval": 593,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold4_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 5,
      "held_out_groups": [
        "coding",
        "content_generation",
        "summarization"
      ],
      "train_groups": [
        "fiction",
        "harmful_request",
        "knowledge_qa",
        "math",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5900153056389928,
          "val_r": 0.7690338245034655,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.4682196748049676,
          "hoo_r": 0.11540519492534332,
          "hoo_n_samples": 526,
          "n_train": 2474,
          "n_eval": 526,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold5_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 6,
      "held_out_groups": [
        "coding",
        "fiction",
        "harmful_request"
      ],
      "train_groups": [
        "content_generation",
        "knowledge_qa",
        "math",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.26555026130434467,
          "val_r": 0.5218377635508313,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -1.3237544888046,
          "hoo_r": 0.35473951522820346,
          "hoo_n_samples": 1000,
          "n_train": 2000,
          "n_eval": 1000,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold6_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 7,
      "held_out_groups": [
        "coding",
        "fiction",
        "knowledge_qa"
      ],
      "train_groups": [
        "content_generation",
        "harmful_request",
        "math",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.6638498998406475,
          "val_r": 0.8151288355208954,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.37022548156561497,
          "hoo_r": 0.18057986812439036,
          "hoo_n_samples": 930,
          "n_train": 2070,
          "n_eval": 930,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold7_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 8,
      "held_out_groups": [
        "coding",
        "fiction",
        "math"
      ],
      "train_groups": [
        "content_generation",
        "harmful_request",
        "knowledge_qa",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5114740216596908,
          "val_r": 0.716554032605434,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -2.7181262529668517,
          "hoo_r": 0.1900887453732823,
          "hoo_n_samples": 958,
          "n_train": 2042,
          "n_eval": 958,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold8_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 9,
      "held_out_groups": [
        "coding",
        "fiction",
        "persuasive_writing"
      ],
      "train_groups": [
        "content_generation",
        "harmful_request",
        "knowledge_qa",
        "math",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5848785361145724,
          "val_r": 0.7651799392044845,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.47140786421252945,
          "hoo_r": 0.18065874365546755,
          "hoo_n_samples": 379,
          "n_train": 2621,
          "n_eval": 379,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold9_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 10,
      "held_out_groups": [
        "coding",
        "fiction",
        "summarization"
      ],
      "train_groups": [
        "content_generation",
        "harmful_request",
        "knowledge_qa",
        "math",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5775101071433653,
          "val_r": 0.7606065142821746,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.4365003942676988,
          "hoo_r": 0.1612975451505783,
          "hoo_n_samples": 312,
          "n_train": 2688,
          "n_eval": 312,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold10_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 11,
      "held_out_groups": [
        "coding",
        "harmful_request",
        "knowledge_qa"
      ],
      "train_groups": [
        "content_generation",
        "fiction",
        "math",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.3011902982295435,
          "val_r": 0.5540481639432089,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.9628141596578024,
          "hoo_r": 0.4002065874000856,
          "hoo_n_samples": 1483,
          "n_train": 1517,
          "n_eval": 1483,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold11_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 12,
      "held_out_groups": [
        "coding",
        "harmful_request",
        "math"
      ],
      "train_groups": [
        "content_generation",
        "fiction",
        "knowledge_qa",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.21694181029405063,
          "val_r": 0.47475234887462864,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.1579302759887995,
          "hoo_r": 0.4407717130365272,
          "hoo_n_samples": 1511,
          "n_train": 1489,
          "n_eval": 1511,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold12_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 13,
      "held_out_groups": [
        "coding",
        "harmful_request",
        "persuasive_writing"
      ],
      "train_groups": [
        "content_generation",
        "fiction",
        "knowledge_qa",
        "math",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.2585269578515727,
          "val_r": 0.5128113966960631,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -2.0753720850423876,
          "hoo_r": 0.4225656554647279,
          "hoo_n_samples": 932,
          "n_train": 2068,
          "n_eval": 932,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold13_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 14,
      "held_out_groups": [
        "coding",
        "harmful_request",
        "summarization"
      ],
      "train_groups": [
        "content_generation",
        "fiction",
        "knowledge_qa",
        "math",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.25679229010131194,
          "val_r": 0.5123743148214425,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -3.06417299218115,
          "hoo_r": 0.3615044976814134,
          "hoo_n_samples": 865,
          "n_train": 2135,
          "n_eval": 865,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold14_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 15,
      "held_out_groups": [
        "coding",
        "knowledge_qa",
        "math"
      ],
      "train_groups": [
        "content_generation",
        "fiction",
        "harmful_request",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5885791208959791,
          "val_r": 0.7679827252265221,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -2.007664548085251,
          "hoo_r": 0.16887209843073323,
          "hoo_n_samples": 1441,
          "n_train": 1559,
          "n_eval": 1441,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold15_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 16,
      "held_out_groups": [
        "coding",
        "knowledge_qa",
        "persuasive_writing"
      ],
      "train_groups": [
        "content_generation",
        "fiction",
        "harmful_request",
        "math",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.65614055132743,
          "val_r": 0.8105847453561943,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.26267084068183344,
          "hoo_r": 0.1818071455039634,
          "hoo_n_samples": 862,
          "n_train": 2138,
          "n_eval": 862,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold16_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 17,
      "held_out_groups": [
        "coding",
        "knowledge_qa",
        "summarization"
      ],
      "train_groups": [
        "content_generation",
        "fiction",
        "harmful_request",
        "math",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.6500863304791075,
          "val_r": 0.8069014282379762,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.2156264538053052,
          "hoo_r": 0.160392870360608,
          "hoo_n_samples": 795,
          "n_train": 2205,
          "n_eval": 795,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold17_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 18,
      "held_out_groups": [
        "coding",
        "math",
        "persuasive_writing"
      ],
      "train_groups": [
        "content_generation",
        "fiction",
        "harmful_request",
        "knowledge_qa",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5175355808915282,
          "val_r": 0.7202807689021323,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -2.56241812138082,
          "hoo_r": 0.1599708198758167,
          "hoo_n_samples": 890,
          "n_train": 2110,
          "n_eval": 890,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold18_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 19,
      "held_out_groups": [
        "coding",
        "math",
        "summarization"
      ],
      "train_groups": [
        "content_generation",
        "fiction",
        "harmful_request",
        "knowledge_qa",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5183774019474778,
          "val_r": 0.7213749169635097,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -2.716590295725966,
          "hoo_r": 0.10726105185605034,
          "hoo_n_samples": 823,
          "n_train": 2177,
          "n_eval": 823,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold19_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 20,
      "held_out_groups": [
        "coding",
        "persuasive_writing",
        "summarization"
      ],
      "train_groups": [
        "content_generation",
        "fiction",
        "harmful_request",
        "knowledge_qa",
        "math"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5730312867791436,
          "val_r": 0.7575502116907534,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.23505621807255417,
          "hoo_r": 0.20272215226234735,
          "hoo_n_samples": 244,
          "n_train": 2756,
          "n_eval": 244,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold20_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 21,
      "held_out_groups": [
        "content_generation",
        "fiction",
        "harmful_request"
      ],
      "train_groups": [
        "coding",
        "knowledge_qa",
        "math",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.26259792537725996,
          "val_r": 0.5210461581749459,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.6801435475152366,
          "hoo_r": 0.3128689167867562,
          "hoo_n_samples": 1250,
          "n_train": 1750,
          "n_eval": 1250,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold21_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 22,
      "held_out_groups": [
        "content_generation",
        "fiction",
        "knowledge_qa"
      ],
      "train_groups": [
        "coding",
        "harmful_request",
        "math",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.6876909693779607,
          "val_r": 0.8296187717697656,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.6486081484353596,
          "hoo_r": 0.1283961963011455,
          "hoo_n_samples": 1180,
          "n_train": 1820,
          "n_eval": 1180,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold22_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 23,
      "held_out_groups": [
        "content_generation",
        "fiction",
        "math"
      ],
      "train_groups": [
        "coding",
        "harmful_request",
        "knowledge_qa",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.4932488725717321,
          "val_r": 0.703820064145149,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -2.983257603750406,
          "hoo_r": 0.23388381221994292,
          "hoo_n_samples": 1208,
          "n_train": 1792,
          "n_eval": 1208,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold23_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 24,
      "held_out_groups": [
        "content_generation",
        "fiction",
        "persuasive_writing"
      ],
      "train_groups": [
        "coding",
        "harmful_request",
        "knowledge_qa",
        "math",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.6043922709179388,
          "val_r": 0.777820358166111,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.7019182740854397,
          "hoo_r": 0.1318212625225107,
          "hoo_n_samples": 629,
          "n_train": 2371,
          "n_eval": 629,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold24_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 25,
      "held_out_groups": [
        "content_generation",
        "fiction",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "harmful_request",
        "knowledge_qa",
        "math",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5895533415518018,
          "val_r": 0.768486383820491,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.6578043084023695,
          "hoo_r": 0.1518803830813773,
          "hoo_n_samples": 562,
          "n_train": 2438,
          "n_eval": 562,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold25_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 26,
      "held_out_groups": [
        "content_generation",
        "harmful_request",
        "knowledge_qa"
      ],
      "train_groups": [
        "coding",
        "fiction",
        "math",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.3177856452779743,
          "val_r": 0.5707849698545144,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.6649463913186031,
          "hoo_r": 0.31936464632999134,
          "hoo_n_samples": 1733,
          "n_train": 1267,
          "n_eval": 1733,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold26_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 27,
      "held_out_groups": [
        "content_generation",
        "harmful_request",
        "math"
      ],
      "train_groups": [
        "coding",
        "fiction",
        "knowledge_qa",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.16602515647574748,
          "val_r": 0.426987025469156,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.06834843190886963,
          "hoo_r": 0.4082407516469821,
          "hoo_n_samples": 1761,
          "n_train": 1239,
          "n_eval": 1761,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold27_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 28,
      "held_out_groups": [
        "content_generation",
        "harmful_request",
        "persuasive_writing"
      ],
      "train_groups": [
        "coding",
        "fiction",
        "knowledge_qa",
        "math",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.24562191475427247,
          "val_r": 0.5036921274013372,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.9255138365244744,
          "hoo_r": 0.3805921838874829,
          "hoo_n_samples": 1182,
          "n_train": 1818,
          "n_eval": 1182,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold28_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 29,
      "held_out_groups": [
        "content_generation",
        "harmful_request",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "fiction",
        "knowledge_qa",
        "math",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.24273645955772336,
          "val_r": 0.5014040451221347,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -1.1321646608841518,
          "hoo_r": 0.3742766765194158,
          "hoo_n_samples": 1115,
          "n_train": 1885,
          "n_eval": 1115,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold29_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 30,
      "held_out_groups": [
        "content_generation",
        "knowledge_qa",
        "math"
      ],
      "train_groups": [
        "coding",
        "fiction",
        "harmful_request",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5555371812875842,
          "val_r": 0.7489676125146916,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -2.8698382264001037,
          "hoo_r": 0.17861268239173675,
          "hoo_n_samples": 1691,
          "n_train": 1309,
          "n_eval": 1691,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold30_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 31,
      "held_out_groups": [
        "content_generation",
        "knowledge_qa",
        "persuasive_writing"
      ],
      "train_groups": [
        "coding",
        "fiction",
        "harmful_request",
        "math",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.6834645398999788,
          "val_r": 0.8277813171205377,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.525422148029026,
          "hoo_r": 0.078879422250339,
          "hoo_n_samples": 1112,
          "n_train": 1888,
          "n_eval": 1112,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold31_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 32,
      "held_out_groups": [
        "content_generation",
        "knowledge_qa",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "fiction",
        "harmful_request",
        "math",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.6694373427769642,
          "val_r": 0.819207290986063,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.4524305140122573,
          "hoo_r": 0.10178008340067012,
          "hoo_n_samples": 1045,
          "n_train": 1955,
          "n_eval": 1045,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold32_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 33,
      "held_out_groups": [
        "content_generation",
        "math",
        "persuasive_writing"
      ],
      "train_groups": [
        "coding",
        "fiction",
        "harmful_request",
        "knowledge_qa",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5032610363575089,
          "val_r": 0.7113148517362887,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -2.7520173185320704,
          "hoo_r": 0.1945653103095522,
          "hoo_n_samples": 1140,
          "n_train": 1860,
          "n_eval": 1140,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold33_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 34,
      "held_out_groups": [
        "content_generation",
        "math",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "fiction",
        "harmful_request",
        "knowledge_qa",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5035256785706567,
          "val_r": 0.7120092048492274,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -2.7593799985283876,
          "hoo_r": 0.15971615348651652,
          "hoo_n_samples": 1073,
          "n_train": 1927,
          "n_eval": 1073,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold34_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 35,
      "held_out_groups": [
        "content_generation",
        "persuasive_writing",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "fiction",
        "harmful_request",
        "knowledge_qa",
        "math"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5838055102668707,
          "val_r": 0.7649553151209609,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.5103743585886868,
          "hoo_r": 0.1363859219507521,
          "hoo_n_samples": 494,
          "n_train": 2506,
          "n_eval": 494,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold35_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 36,
      "held_out_groups": [
        "fiction",
        "harmful_request",
        "knowledge_qa"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "math",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.3042601001369055,
          "val_r": 0.5574106837764387,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.7224995399541625,
          "hoo_r": 0.40852439084403597,
          "hoo_n_samples": 1519,
          "n_train": 1481,
          "n_eval": 1519,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold36_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 37,
      "held_out_groups": [
        "fiction",
        "harmful_request",
        "math"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "knowledge_qa",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.1656836221933007,
          "val_r": 0.42745208474453306,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.09531016324766961,
          "hoo_r": 0.4483440114957471,
          "hoo_n_samples": 1547,
          "n_train": 1453,
          "n_eval": 1547,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold37_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 38,
      "held_out_groups": [
        "fiction",
        "harmful_request",
        "persuasive_writing"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "knowledge_qa",
        "math",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.25903584236879146,
          "val_r": 0.5155840580128238,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -1.3256001581435193,
          "hoo_r": 0.3292525417339597,
          "hoo_n_samples": 968,
          "n_train": 2032,
          "n_eval": 968,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold38_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 39,
      "held_out_groups": [
        "fiction",
        "harmful_request",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "knowledge_qa",
        "math",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.2531486520375167,
          "val_r": 0.5106141910242309,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -1.769552513403775,
          "hoo_r": 0.29924466103784114,
          "hoo_n_samples": 901,
          "n_train": 2099,
          "n_eval": 901,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold39_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 40,
      "held_out_groups": [
        "fiction",
        "knowledge_qa",
        "math"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "harmful_request",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5607921639166109,
          "val_r": 0.7493499968456406,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -2.2831057590210384,
          "hoo_r": 0.19714460271696593,
          "hoo_n_samples": 1477,
          "n_train": 1523,
          "n_eval": 1477,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold40_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 41,
      "held_out_groups": [
        "fiction",
        "knowledge_qa",
        "persuasive_writing"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "harmful_request",
        "math",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.6577907657897877,
          "val_r": 0.8113511766632616,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.38539114738552493,
          "hoo_r": 0.1684563143005363,
          "hoo_n_samples": 898,
          "n_train": 2102,
          "n_eval": 898,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold41_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 42,
      "held_out_groups": [
        "fiction",
        "knowledge_qa",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "harmful_request",
        "math",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.6478088772657029,
          "val_r": 0.8051751113102436,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.3322773382722357,
          "hoo_r": 0.1675731940412304,
          "hoo_n_samples": 831,
          "n_train": 2169,
          "n_eval": 831,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold42_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 43,
      "held_out_groups": [
        "fiction",
        "math",
        "persuasive_writing"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "harmful_request",
        "knowledge_qa",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5046415001440957,
          "val_r": 0.7112522534401431,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -2.8573557157175045,
          "hoo_r": 0.18723014411340191,
          "hoo_n_samples": 926,
          "n_train": 2074,
          "n_eval": 926,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold43_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 44,
      "held_out_groups": [
        "fiction",
        "math",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "harmful_request",
        "knowledge_qa",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5054037817722515,
          "val_r": 0.7123707148619616,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -3.0116282895760644,
          "hoo_r": 0.15802335899141604,
          "hoo_n_samples": 859,
          "n_train": 2141,
          "n_eval": 859,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold44_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 45,
      "held_out_groups": [
        "fiction",
        "persuasive_writing",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "harmful_request",
        "knowledge_qa",
        "math"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5741507432518559,
          "val_r": 0.7581169217253443,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.5068419992765476,
          "hoo_r": 0.20337565947417208,
          "hoo_n_samples": 280,
          "n_train": 2720,
          "n_eval": 280,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold45_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 46,
      "held_out_groups": [
        "harmful_request",
        "knowledge_qa",
        "math"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "fiction",
        "persuasive_writing",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.24420761763803425,
          "val_r": 0.5075469294557969,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.10482273350429261,
          "hoo_r": 0.4556871540528121,
          "hoo_n_samples": 2030,
          "n_train": 970,
          "n_eval": 2030,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold46_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 47,
      "held_out_groups": [
        "harmful_request",
        "knowledge_qa",
        "persuasive_writing"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "fiction",
        "math",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.2864267936803019,
          "val_r": 0.5410538179521402,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.9324087884779926,
          "hoo_r": 0.42128496229108675,
          "hoo_n_samples": 1451,
          "n_train": 1549,
          "n_eval": 1451,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold47_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 48,
      "held_out_groups": [
        "harmful_request",
        "knowledge_qa",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "fiction",
        "math",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.2852555688996111,
          "val_r": 0.5409790186491495,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -1.0804732764455447,
          "hoo_r": 0.38347871186289767,
          "hoo_n_samples": 1384,
          "n_train": 1616,
          "n_eval": 1384,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold48_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 49,
      "held_out_groups": [
        "harmful_request",
        "math",
        "persuasive_writing"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "fiction",
        "knowledge_qa",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.18019755896187492,
          "val_r": 0.43851974491927204,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.15057639341929407,
          "hoo_r": 0.42325980481867403,
          "hoo_n_samples": 1479,
          "n_train": 1521,
          "n_eval": 1479,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold49_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 50,
      "held_out_groups": [
        "harmful_request",
        "math",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "fiction",
        "knowledge_qa",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.1881345116697956,
          "val_r": 0.44837778558495306,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.18604627860076128,
          "hoo_r": 0.41811127157222827,
          "hoo_n_samples": 1412,
          "n_train": 1588,
          "n_eval": 1412,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold50_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 51,
      "held_out_groups": [
        "harmful_request",
        "persuasive_writing",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "fiction",
        "knowledge_qa",
        "math"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.24579225972598168,
          "val_r": 0.501355733607488,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -3.200462143271447,
          "hoo_r": 0.3714873510869692,
          "hoo_n_samples": 833,
          "n_train": 2167,
          "n_eval": 833,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold51_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 52,
      "held_out_groups": [
        "knowledge_qa",
        "math",
        "persuasive_writing"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "fiction",
        "harmful_request",
        "summarization"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5710150443904609,
          "val_r": 0.7563177427402639,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -2.005785292321202,
          "hoo_r": 0.19120411780603033,
          "hoo_n_samples": 1409,
          "n_train": 1591,
          "n_eval": 1409,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold52_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 53,
      "held_out_groups": [
        "knowledge_qa",
        "math",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "fiction",
        "harmful_request",
        "persuasive_writing"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5768829856176675,
          "val_r": 0.7606170053405858,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -1.8918468547835312,
          "hoo_r": 0.1657355804099785,
          "hoo_n_samples": 1342,
          "n_train": 1658,
          "n_eval": 1342,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold53_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 54,
      "held_out_groups": [
        "knowledge_qa",
        "persuasive_writing",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "fiction",
        "harmful_request",
        "math"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.6413436149188676,
          "val_r": 0.8013241949224879,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -0.2267560240724611,
          "hoo_r": 0.16949654997316552,
          "hoo_n_samples": 763,
          "n_train": 2237,
          "n_eval": 763,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold54_ridge_L00",
          "layer": 0
        }
      }
    },
    {
      "fold_idx": 55,
      "held_out_groups": [
        "math",
        "persuasive_writing",
        "summarization"
      ],
      "train_groups": [
        "coding",
        "content_generation",
        "fiction",
        "harmful_request",
        "knowledge_qa"
      ],
      "layers": {
        "ridge_L0": {
          "val_r2": 0.5099152373622129,
          "val_r": 0.7150875709662727,
          "best_alpha": 464.15888336127773,
          "hoo_r2": -2.9149660750785276,
          "hoo_r": 0.13527582544842703,
          "hoo_n_samples": 791,
          "n_train": 2209,
          "n_eval": 791,
          "demean_confounds": null,
          "method": "ridge",
          "probe_id": "hoo_fold55_ridge_L00",
          "layer": 0
        }
      }
    }
  ],
  "layer_summary": {
    "0": {
      "ridge": {
        "mean_val_r": 0.6672766628500152,
        "mean_hoo_r": 0.24450707948841768,
        "std_hoo_r": 0.11637789441218069,
        "n_folds": 56
      }
    }
  }
}