fitting_method: active_learning
converged: true
neg_log_likelihood: 16990.996328228623
n_iterations: 70
n_function_evals: 73
termination_message: 'CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL'
gradient_norm: 23.933427032834288
history:
  loss:
  - 22236.36721963998
  - 19773.796255123627
  - 19276.61542450697
  - 18337.770363668416
  - 18064.771281496905
  - 17847.23213316735
  - 17727.701229848164
  - 17599.70674067009
  - 17548.932989333363
  - 17496.486929300077
  - 17436.48938516323
  - 17398.262025572345
  - 17358.954531303338
  - 17317.981480727125
  - 17294.71906810977
  - 17264.37401166013
  - 17236.272376340494
  - 17213.52920812503
  - 17194.098076734506
  - 17173.14007636992
  - 17156.051919330843
  - 17141.1568776345
  - 17127.457547790465
  - 17118.80722558318
  - 17107.191584430955
  - 17099.59173967217
  - 17093.15498252136
  - 17089.843961600498
  - 17084.745442969717
  - 17080.157567919487
  - 17074.461457959856
  - 17070.324329044182
  - 17065.34913424783
  - 17060.127465118192
  - 17053.68077131545
  - 17047.593965466433
  - 17041.704010638863
  - 17036.53314613729
  - 17030.12471155418
  - 17025.742777277086
  - 17022.06269351354
  - 17018.735599002615
  - 17016.843012607336
  - 17015.18937307638
  - 17012.998149700346
  - 17011.468688827852
  - 17009.441300960738
  - 17008.032427517574
  - 17006.812629764725
  - 17005.330396000114
  - 17004.21092523337
  - 17002.9678665816
  - 17001.86166634986
  - 17000.7191302997
  - 16999.53816482888
  - 16998.044015418098
  - 16997.262582701656
  - 16996.17275457181
  - 16995.660138681185
  - 16994.6484726638
  - 16994.150757115098
  - 16993.65601348191
  - 16992.802279363932
  - 16992.568587498536
  - 16991.927465233104
  - 16991.76126478667
  - 16991.527475297953
  - 16991.462875304187
  - 16991.132858148816
  - 16990.996328228623
  sigma_max:
  - 1.0
  - 2.431942320674255
  - 2.7461745299732554
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
config:
  n_tasks: 500
  seed: 42
  generation_seed: 2
