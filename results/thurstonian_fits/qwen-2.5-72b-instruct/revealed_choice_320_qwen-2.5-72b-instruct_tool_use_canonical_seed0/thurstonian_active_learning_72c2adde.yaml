fitting_method: active_learning
converged: true
neg_log_likelihood: 17455.398906492
n_iterations: 64
n_function_evals: 68
termination_message: 'CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL'
gradient_norm: 40.945862904450834
history:
  loss:
  - 26172.28844422919
  - 22034.380585379327
  - 21318.28147377166
  - 19703.888895206666
  - 19126.979104684306
  - 18779.409773549636
  - 18472.035351981438
  - 18249.45642372471
  - 18117.464431123975
  - 18028.19356546724
  - 17976.977883579228
  - 17893.455320974128
  - 17850.69918684883
  - 17805.0852583719
  - 17775.5856323079
  - 17746.411648372323
  - 17706.84687444134
  - 17674.750831029116
  - 17657.341841228405
  - 17627.816405337395
  - 17616.813696280726
  - 17598.974181706537
  - 17587.185023589955
  - 17577.606407433082
  - 17561.77338565834
  - 17555.00213440161
  - 17543.5465235986
  - 17536.155368975535
  - 17529.77096979801
  - 17520.62551423322
  - 17515.77824730297
  - 17506.84271502082
  - 17500.779106678045
  - 17496.22078278484
  - 17489.265690809614
  - 17485.921482041813
  - 17480.228984068734
  - 17477.701941823052
  - 17474.954745131403
  - 17472.86770304129
  - 17470.30406866182
  - 17468.800891024766
  - 17467.590921254945
  - 17466.402539410712
  - 17465.4732076366
  - 17464.6193358581
  - 17463.92904310241
  - 17462.977927599768
  - 17462.068603942604
  - 17461.154732948373
  - 17460.55970304975
  - 17459.965373342726
  - 17459.534834977316
  - 17459.04395399529
  - 17458.38809698463
  - 17458.070985672366
  - 17457.638145316934
  - 17457.322887698057
  - 17456.9586296129
  - 17456.675937763714
  - 17456.356751740746
  - 17455.93994064925
  - 17455.67347133757
  - 17455.398906492
  sigma_max:
  - 1.0
  - 3.1762375604078694
  - 3.7070365832585903
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
config:
  n_tasks: 500
  seed: 42
  generation_seed: 0
