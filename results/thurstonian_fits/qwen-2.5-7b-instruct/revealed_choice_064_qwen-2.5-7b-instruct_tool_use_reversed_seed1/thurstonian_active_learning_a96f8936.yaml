fitting_method: active_learning
converged: true
neg_log_likelihood: 16293.461423767181
n_iterations: 65
n_function_evals: 68
termination_message: 'CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL'
gradient_norm: 17.983332946716146
history:
  loss:
  - 21763.802435699177
  - 19184.04310682531
  - 18607.199392341896
  - 17489.199868631134
  - 17231.871732675707
  - 17007.249795154334
  - 16928.76652059274
  - 16844.789489925963
  - 16743.416083256554
  - 16680.285427098926
  - 16634.455279797086
  - 16596.89506800662
  - 16559.61502118488
  - 16525.03592587256
  - 16494.06743781634
  - 16476.069814550545
  - 16450.88376751428
  - 16438.852597397534
  - 16424.9073660127
  - 16415.9372318174
  - 16408.232509786256
  - 16399.759679774856
  - 16391.219302246835
  - 16386.30561306319
  - 16379.196273032267
  - 16369.511017922276
  - 16364.28731911757
  - 16359.213998917503
  - 16355.937641085982
  - 16352.766541768526
  - 16346.916691651297
  - 16343.051319954402
  - 16340.002206105552
  - 16337.6424912819
  - 16335.108143838612
  - 16330.89761145301
  - 16328.515776335369
  - 16326.488192996603
  - 16324.531427090697
  - 16323.285903429689
  - 16318.816130524923
  - 16318.11772269455
  - 16314.530129551913
  - 16312.456510726373
  - 16310.359852463325
  - 16307.449153962454
  - 16305.865511394535
  - 16303.897337043427
  - 16302.253067396325
  - 16301.140753074475
  - 16300.123502086792
  - 16299.223431497634
  - 16298.308317847142
  - 16297.631898147405
  - 16297.154177455108
  - 16296.613014261493
  - 16296.15452970223
  - 16295.703054929498
  - 16295.37603785409
  - 16295.138531549526
  - 16294.848716610182
  - 16294.342235534432
  - 16293.968205763138
  - 16293.68678391057
  - 16293.461423767181
  sigma_max:
  - 1.0
  - 2.5099151626010587
  - 3.0695980310528226
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
config:
  n_tasks: 500
  seed: 42
  generation_seed: 1
