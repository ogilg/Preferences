fitting_method: active_learning
converged: true
neg_log_likelihood: 16726.69310234772
n_iterations: 69
n_function_evals: 72
termination_message: 'CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL'
gradient_norm: 18.285538621906557
history:
  loss:
  - 23575.50070830897
  - 20619.359765376525
  - 19842.599170863632
  - 18274.59133533506
  - 17969.653800702916
  - 17603.010333957725
  - 17488.3873025069
  - 17302.681229164562
  - 17184.303990500313
  - 17098.77057626241
  - 17045.067734150693
  - 17011.583704386296
  - 16969.66659436671
  - 16949.7344209402
  - 16928.58736576988
  - 16907.57746051011
  - 16892.501342332736
  - 16872.300259118416
  - 16858.511740377035
  - 16849.606020005398
  - 16839.50583329348
  - 16832.77313404562
  - 16827.53566720774
  - 16819.439551334515
  - 16814.482653060197
  - 16809.44770732936
  - 16802.99949654387
  - 16799.30265227931
  - 16794.972530454765
  - 16790.275038278112
  - 16785.525980691884
  - 16781.146890840682
  - 16777.127769209903
  - 16773.594729295586
  - 16770.80587801178
  - 16766.391334808694
  - 16763.275628235086
  - 16759.316762746304
  - 16755.646922234468
  - 16752.877762778237
  - 16750.741888596647
  - 16747.245797724096
  - 16746.141773875013
  - 16744.656794217815
  - 16743.203210995358
  - 16742.289716598545
  - 16741.25176165902
  - 16740.414917453636
  - 16739.315379846514
  - 16738.19966662019
  - 16737.340277954423
  - 16736.000635109256
  - 16735.00670374896
  - 16733.73501979231
  - 16732.764661976074
  - 16732.210887892466
  - 16731.616062228222
  - 16730.729924828855
  - 16730.3030469896
  - 16729.49021830716
  - 16729.09695893076
  - 16728.621789918892
  - 16728.23392842481
  - 16727.78819705716
  - 16727.58616927458
  - 16727.366267112833
  - 16727.13967249284
  - 16726.88897636888
  - 16726.69310234772
  sigma_max:
  - 1.0
  - 2.3679448337851023
  - 2.977540538035269
  - 7.211291286162005
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
  - 7.38905609893065
config:
  n_tasks: 500
  seed: 42
  generation_seed: 0
