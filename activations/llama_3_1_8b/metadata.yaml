last_updated: '2026-01-16T17:30:47.631930'
layers_config:
- 0.25
- 0.5
- 0.75
layers_resolved:
- 8
- 16
- 24
max_new_tokens: 1024
model: llama-3.1-8b
n_existing: 1000
n_failures: 0
n_model_layers: 32
n_new: 8500
n_ooms: 0
n_tasks: 10000
n_truncated: 650
seed: 42
task_origins:
- 1
- 2
- 3
- 5
temperature: 1.0
